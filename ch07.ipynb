{
 "cells": [
  {
   "cell_type": "raw",
   "id": "professional-partnership",
   "metadata": {},
   "source": [
    "[[ch07]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-blackjack",
   "metadata": {},
   "source": [
    "# Tranformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-spread",
   "metadata": {},
   "source": [
    "## Building a Transformer from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Transformer()\n",
    "model.encoder.layers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-hygiene",
   "metadata": {},
   "source": [
    "## Attention Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-chassis",
   "metadata": {},
   "source": [
    "### Dot Product Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-acoustic",
   "metadata": {},
   "source": [
    "### Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dots = [\n",
    "    np.dot(np.random.randn(10),\n",
    "           np.random.randn(10))\n",
    "    for i in range(100)]\n",
    "np.mean(np.absolute(small_dots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_dots = [np.dot(np.random.randn(10000),\n",
    "                     np.random.randn(10000))\n",
    "              for i in range(100)]\n",
    "np.mean(np.absolute(large_dots))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-plastic",
   "metadata": {},
   "source": [
    "### Multi Head Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-fruit",
   "metadata": {},
   "source": [
    "### Adaptive Attention Span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-helicopter",
   "metadata": {},
   "source": [
    "### Persistent Memory/All-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-trigger",
   "metadata": {},
   "source": [
    "### Product-Key Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-vacuum",
   "metadata": {},
   "source": [
    "## Transformers for Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77022a5d-a34f-4c1f-87a1-4e537eb4d3ce",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT for sentiment analysis\n",
    "\n",
    "## Contents\n",
    "1. 학습데이터 확인\n",
    "2. 보조함수 확인\n",
    "3. SenitmentClassifier 확인\n",
    "4. Analyser 확인\n",
    "5. 학습 과정 확인\n",
    "6. tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19e501-b550-427c-b4dd-e328536b7133",
   "metadata": {},
   "source": [
    "## 학습 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7b518-8c06-4a6a-a661-1efc6b058d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install transformers\n",
    "from typing import List, Tuple\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "DATA: List[Tuple[str, int]] = [\n",
    "    # 긍정적인 문장 - 1\n",
    "    (\"난 너를 좋아해\", 1),\n",
    "    # --- 부정적인 문장 - 레이블 = 0\n",
    "    (\"난 너를 싫어해\", 0)\n",
    "]\n",
    "\n",
    "TESTS = [\n",
    "    \"나는 자연어처리가 좋아\",\n",
    "    \"나는 자연어처리가 싫어\",\n",
    "    \"나는 너가 좋다\",\n",
    "    \"너는 참 좋다\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c9831-f8a8-477e-b7b5-9277b590a3a5",
   "metadata": {},
   "source": [
    "## 보조함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ae08b-1d45-4d5c-a6a2-00d404deb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda를 사용할 수 있는지를 체크, 사용가능하다면 cuda로 설정된 device를 출력.\n",
    "def load_device() -> torch.device:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return device\n",
    "\n",
    "\n",
    "# 텐서를 구축하는 부분 - X\n",
    "def build_X(sents: List[str], tokenizer: BertTokenizer, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    return X (N, 3, L).  N, 0, L -> input_ids / N, 1, L -> token_type_ids / N, 2, L -> attention_mask\n",
    "    \"\"\"\n",
    "    encodings = tokenizer(text=sents,\n",
    "                          add_special_tokens=True,\n",
    "                          return_tensors='pt',\n",
    "                          truncation=True,\n",
    "                          padding=True)\n",
    "    return torch.stack([\n",
    "        encodings['input_ids'],\n",
    "        encodings['token_type_ids'],\n",
    "        encodings['attention_mask']\n",
    "    ], dim=1).to(device)\n",
    "\n",
    "# 텐서를 구축하는 부분 - y\n",
    "def build_y(labels: List[int], device: torch.device) -> torch.Tensor:\n",
    "    return torch.FloatTensor(labels).unsqueeze(-1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e373fc-a77b-4f7a-b9b1-cf7e2ed16197",
   "metadata": {},
   "source": [
    "## Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5389f-b169-4d33-8dc6-28d0bb54e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(torch.nn.Module):\n",
    "    def __init__(self, bert: BertModel):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.hidden_size = bert.config.hidden_size\n",
    "        # TODO 1\n",
    "        self.W_hy = torch.nn.Linear(..., ...)\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param X: (N, 3, L)\n",
    "        :return: H_all (N, L, H)\n",
    "        \"\"\"\n",
    "        input_ids = X[:, 0]\n",
    "        token_type_ids = X[:, 1]\n",
    "        attention_mask = X[:, 2]\n",
    "        H_all = self.bert(input_ids, token_type_ids, attention_mask)[0]\n",
    "        return H_all\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param X:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # TODO 2\n",
    "        H_all = self.forward(X)\n",
    "        H_cls = ...\n",
    "        y_hat = ...  # (N, H) * (H, 1) -> (N, 1)\n",
    "        return torch.sigmoid(y_hat)\n",
    "\n",
    "    def training_step(self, X: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        # TODO 3\n",
    "        y_hat = self.predict(X)\n",
    "        loss = ...\n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8091b-e8bc-4a94-ad31-cb8ef645869e",
   "metadata": {},
   "source": [
    "## Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457d3aa-ab21-4d18-909b-a6ede707cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Analyser:\n",
    "    \"\"\"\n",
    "    Bert 기반 감성분석기.\n",
    "    \"\"\"\n",
    "    def __init__(self, classifier: SentimentClassifier, tokenizer: BertTokenizer, device: torch.device):\n",
    "        self.classifier = classifier\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, text: str) -> float:\n",
    "        X = build_X(sents=[text], tokenizer=self.tokenizer, device=self.device)\n",
    "        y_hat = self.classifier.predict(X)\n",
    "        return y_hat.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba24e5-8478-442f-9de0-5d18cb35c8a5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584485e-ba13-473c-a64c-8e7add28d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 버트 모델을 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('beomi/kcbert-base')\n",
    "bert = BertModel.from_pretrained('beomi/kcbert-base')\n",
    "\n",
    "# --- have a look at the config --- #\n",
    "print(bert.config)\n",
    "print(bert.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771333dd-2e87-41a9-8fe3-2eb3097437b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- hyper parameters --- #\n",
    "EPOCHS = 20\n",
    "LR = 0.0001\n",
    "\n",
    "\n",
    "device = load_device()\n",
    "print(device)\n",
    "\n",
    "# --- build the dataset --- # \n",
    "sents = [sent for sent, _ in DATA]\n",
    "labels = [label for _, label in DATA]\n",
    "X = build_X(sents, tokenizer, device)\n",
    "y = build_y(labels, device)\n",
    "\n",
    "# --- instantiate the classifier --- #\n",
    "classifier = SentimentClassifier(bert)\n",
    "classifier.to(device)  # 모델도 gpu에 올리기. \n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=LR)  # 최적화 알고리즘을 선택.\n",
    "\n",
    "# --- 학습시작 --- #\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = classifier.training_step(X, y)\n",
    "    loss.backward()  # 오차 역전파\n",
    "    optimizer.step()  # 경사도 하강\n",
    "    optimizer.zero_grad()  # 기울기 축적방지\n",
    "    print(f\"epoch:{epoch}, loss:{loss.item()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d7d13-4b45-4cbe-ba91-02c0670257ba",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9040b5-d9f0-4e3e-b920-e8382b9e124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "analyser = Analyser(classifier, tokenizer, device)\n",
    "\n",
    "for sent in TESTS:\n",
    "    print(sent, \"->\", analyser(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-indicator",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
