{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6b8532a2",
   "metadata": {},
   "source": [
    "[appendix]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156eae1e",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e2f55",
   "metadata": {},
   "source": [
    "## Multi-GPU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Transformer()\n",
    "# model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352afc9d-7ba5-4a55-b38c-2d6db44ba442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = torch.nn.Linear(10, 10).to('cuda:0')\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.net1(x.to('cuda:0')))\n",
    "        return self.net2(x.to('cuda:1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceea2fc-a005-43f1-b4c3-663fcaed3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs = model(torch.randn(20, 10))\n",
    "labels = torch.randn(20, 5).to('cuda:1')\n",
    "loss_fn(outputs, labels).backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11944f02-36ff-4c6c-8bd1-fa31d5021452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "\n",
    "num_classes = 1000\n",
    "\n",
    "class ModelParallelResNet50(ResNet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModelParallelResNet50, self).__init__(\n",
    "            Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)\n",
    "\n",
    "        self.seq1 = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "\n",
    "            self.layer1,\n",
    "            self.layer2\n",
    "        ).to('cuda:0')\n",
    "\n",
    "        self.seq2 = nn.Sequential(\n",
    "            self.layer3,\n",
    "            self.layer4,\n",
    "            self.avgpool,\n",
    "        ).to('cuda:1')\n",
    "\n",
    "        self.fc.to('cuda:1')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq2(self.seq1(x).to('cuda:1'))\n",
    "        return self.fc(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d763c9d-783b-407c-b32a-bdb07cfa153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "num_batches = 3\n",
    "batch_size = 120\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    model.train(True)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "    one_hot_indices = torch.LongTensor(batch_size) \\\n",
    "                           .random_(0, num_classes) \\\n",
    "                           .view(batch_size, 1)\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        # generate random inputs and labels\n",
    "        inputs = torch.randn(batch_size, 3, image_w, image_h)\n",
    "        labels = torch.zeros(batch_size, num_classes) \\\n",
    "                      .scatter_(1, one_hot_indices, 1)\n",
    "\n",
    "        # run forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to('cuda:0'))\n",
    "\n",
    "        # run backward pass\n",
    "        labels = labels.to(outputs.device)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32d825-fd45-4b5b-9722-3d07543c5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('Agg')\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "num_repeat = 10\n",
    "\n",
    "stmt = \"train(model)\"\n",
    "\n",
    "setup = \"model = ModelParallelResNet50()\"\n",
    "mp_run_times = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)\n",
    "\n",
    "setup = \"import torchvision.models as models;\" + \\\n",
    "        \"model = models.resnet50(num_classes=num_classes).to('cuda:0')\"\n",
    "rn_run_times = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)\n",
    "\n",
    "\n",
    "def plot(means, stds, labels, fig_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(np.arange(len(means)), means, yerr=stds,\n",
    "           align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)\n",
    "    ax.set_ylabel('ResNet50 Execution Time (Second)')\n",
    "    ax.set_xticks(np.arange(len(means)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "plot([mp_mean, rn_mean],\n",
    "     [mp_std, rn_std],\n",
    "     ['Model Parallel', 'Single GPU'],\n",
    "     'mp_vs_rn.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac43895-e853-4634-9333-a2eea814bc34",
   "metadata": {},
   "source": [
    "![image](mp_vs_rn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95551ccb-2ae7-402c-9f67-255565d830b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineParallelResNet50(ModelParallelResNet50):\n",
    "    def __init__(self, split_size=20, *args, **kwargs):\n",
    "        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)\n",
    "        self.split_size = split_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        splits = iter(x.split(self.split_size, dim=0))\n",
    "        s_next = next(splits)\n",
    "        s_prev = self.seq1(s_next).to('cuda:1')\n",
    "        ret = []\n",
    "\n",
    "        for s_next in splits:\n",
    "            # A. s_prev runs on cuda:1\n",
    "            s_prev = self.seq2(s_prev)\n",
    "            ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n",
    "\n",
    "            # B. s_next runs on cuda:0, which can run concurrently with A\n",
    "            s_prev = self.seq1(s_next).to('cuda:1')\n",
    "\n",
    "        s_prev = self.seq2(s_prev)\n",
    "        ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n",
    "\n",
    "        return torch.cat(ret)\n",
    "\n",
    "\n",
    "setup = \"model = PipelineParallelResNet50()\"\n",
    "pp_run_times = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "pp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)\n",
    "\n",
    "plot([mp_mean, rn_mean, pp_mean],\n",
    "     [mp_std, rn_std, pp_std],\n",
    "     ['Model Parallel', 'Single GPU', 'Pipelining Model Parallel'],\n",
    "     'mp_vs_rn_vs_pp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4b3ed-31ee-47f9-8383-d595d3272cca",
   "metadata": {},
   "source": [
    "![image](mp_vs_rn_vs_pp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72d4d3-59ad-49ba-802b-f32498e99fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "split_sizes = [1, 3, 5, 8, 10, 12, 20, 40, 60]\n",
    "\n",
    "for split_size in split_sizes:\n",
    "    setup = \"model = PipelineParallelResNet50(split_size=%d)\" % split_size\n",
    "    pp_run_times = timeit.repeat(\n",
    "        stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "    means.append(np.mean(pp_run_times))\n",
    "    stds.append(np.std(pp_run_times))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(split_sizes, means)\n",
    "ax.errorbar(split_sizes, means, yerr=stds, ecolor='red', fmt='ro')\n",
    "ax.set_ylabel('ResNet50 Execution Time (Second)')\n",
    "ax.set_xlabel('Pipeline Split Size')\n",
    "ax.set_xticks(split_sizes)\n",
    "ax.yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"split_size_tradeoff.png\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e49fb-e76c-4c19-a71d-fb10dc8b0686",
   "metadata": {},
   "source": [
    "![image](split_size_tradeoff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ee23e",
   "metadata": {},
   "source": [
    "## Distributed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c7967-5f2e-47a7-8a1d-416f10ad02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# On Windows platform, the torch.distributed package only\n",
    "# supports Gloo backend, FileStore and TcpStore.\n",
    "# For FileStore, set init_method parameter in init_process_group\n",
    "# to a local file. Example as follow:\n",
    "# init_method=\"file:///f:/libtmp/some_file\"\n",
    "# dist.init_process_group(\n",
    "#    \"gloo\",\n",
    "#    rank=rank,\n",
    "#    init_method=init_method,\n",
    "#    world_size=world_size)\n",
    "# For TcpStore, same way as on Linux.\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221acb6-6663-47be-95be-e055113e6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "def demo_basic(rank, world_size):\n",
    "    print(f\"Running basic DDP example on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # create model and move it to GPU with id rank\n",
    "    model = ToyModel().to(rank)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ddp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(rank)\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "def run_demo(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,),\n",
    "             nprocs=world_size,\n",
    "             join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c77e5-daf5-442f-a8b9-09bce5b21579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_checkpoint(rank, world_size):\n",
    "    print(f\"Running DDP checkpoint example on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    model = ToyModel().to(rank)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "\n",
    "    CHECKPOINT_PATH = tempfile.gettempdir() + \"/model.checkpoint\"\n",
    "    if rank == 0:\n",
    "        # All processes should see same parameters as they all start from same\n",
    "        # random parameters and gradients are synchronized in backward passes.\n",
    "        # Therefore, saving it in one process is sufficient.\n",
    "        torch.save(ddp_model.state_dict(), CHECKPOINT_PATH)\n",
    "\n",
    "    # Use a barrier() to make sure that process 1 loads the model after process\n",
    "    # 0 saves it.\n",
    "    dist.barrier()\n",
    "    # configure map_location properly\n",
    "    map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}\n",
    "    ddp_model.load_state_dict(\n",
    "        torch.load(CHECKPOINT_PATH, map_location=map_location))\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ddp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(rank)\n",
    "\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Not necessary to use a dist.barrier() to guard the file deletion below\n",
    "    # as the AllReduce ops in the backward pass of DDP already served as\n",
    "    # a synchronization.\n",
    "\n",
    "    if rank == 0:\n",
    "        os.remove(CHECKPOINT_PATH)\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7cd671-075c-45e5-8b28-5f2ee47de007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyMpModel(nn.Module):\n",
    "    def __init__(self, dev0, dev1):\n",
    "        super(ToyMpModel, self).__init__()\n",
    "        self.dev0 = dev0\n",
    "        self.dev1 = dev1\n",
    "        self.net1 = torch.nn.Linear(10, 10).to(dev0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(10, 5).to(dev1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.dev0)\n",
    "        x = self.relu(self.net1(x))\n",
    "        x = x.to(self.dev1)\n",
    "        return self.net2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa419fd9-8089-40c7-92f6-026c9893a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_model_parallel(rank, world_size):\n",
    "    print(f\"Running DDP with model parallel example on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # setup mp_model and devices for this process\n",
    "    dev0 = (rank * 2) % world_size\n",
    "    dev1 = (rank * 2 + 1) % world_size\n",
    "    mp_model = ToyMpModel(dev0, dev1)\n",
    "    ddp_mp_model = DDP(mp_model)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # outputs will be on dev1\n",
    "    outputs = ddp_mp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(dev1)\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    assert n_gpus >= 2, f\"Requires at least 2 GPUs to run, but got {n_gpus}\"\n",
    "    world_size = n_gpus\n",
    "    run_demo(demo_basic, world_size)\n",
    "    run_demo(demo_checkpoint, world_size)\n",
    "    run_demo(demo_model_parallel, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a3988-cac6-4f2d-a9a8-eea3c895807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "def demo_basic():\n",
    "    dist.init_process_group(\"nccl\")\n",
    "    rank = dist.get_rank()\n",
    "    print(f\"Start running basic DDP example on rank {rank}.\")\n",
    "\n",
    "    # create model and move it to GPU with id rank\n",
    "    device_id = rank % torch.cuda.device_count()\n",
    "    model = ToyModel().to(device_id)\n",
    "    ddp_model = DDP(model, device_ids=[device_id])\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ddp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(device_id)\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_basic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022478a8",
   "metadata": {},
   "source": [
    "## What Makes Deep Training fast?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
