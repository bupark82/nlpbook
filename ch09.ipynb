{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ch09]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools of the Trade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 섹션에서는 NLP의 모든 기본 요소와 NLP 모델을 개발하는 방법을 다루었습니다. 이 장을 시작으로, 신중하게 큐레이팅된 데이터 세트에서 멋진 모델을 교육하는 멋진 세계에서 나올 때 생각하기 시작해야 할 사항과 현실 세계인 혼란 속을 다룰 것입니다.\n",
    "\n",
    "이 장에서는 구체적으로 주류 기계 학습 소프트웨어와 스택에 포함할 항목을 결정할 때 직면하게 될 선택 사항에 대해 설명합니다. 그런 다음 10장에서는 Streamlit(https://streamlit.io)이라는 사용하기 쉬운 오픈 소스 Python 라이브러리를 사용하여 기계 학습 및 데이터 과학을 위한 사용자 지정 웹 앱을 구축하고 (11장에서)업계 리더인 Databricks(https://databricks.com)의 소프트웨어를 사용하여 규모에 맞게 모델을 배포하는 것으로 이 섹션을 마무리합니다. 이 세 장을 마치면 기계 학습 모델을 웹 앱, API 및 기계 학습 파이프라인으로 생산하는 방법을 잘 이해할 수 있습니다.\n",
    "\n",
    "많은 개발자들이 지나치게 많은 시간을 두고 논쟁하는 것을 좋아하는 주제인 도구부터 시작하겠습니다.\n",
    "\n",
    "코딩에 시간을 할애해야 하는 사람들은 표준 TensorFlow 대 PyTorch 또는 끝없이 긴 Twitter 스레드에서 최고의 프로그래밍 언어 토론을 해싱하는 것을 좋아하지만 한 걸음 물러서서 좀 더 실용적인 결정에 대해 이야기하고 싶습니다. 당신은 현실 세계에서 씨름해야합니다. 결국 \"응용\"은 이 책의 제목이다.\n",
    "\n",
    "다음은 몇 가지 의무 면책 조항입니다.\n",
    "\n",
    "- 오늘 우리가 추천하는 것은 시간이 지나면 구식이 될 것이 거의 확실합니다. 우리의 조언에 지나치게 규범적이지 않고 기술 스택에 포함할 결정을 내릴 때 중요한 사항에 대한 직관을 개발하도록 돕고 싶습니다.\n",
    "\n",
    "- 예를 들어 회사에서 이미 사용해야 하는 일련의 도구가 있을 수 있습니다. 또는 프로그래밍 언어, 클라우드 공급자 등을 이미 선택한 대규모 팀의 일원일 수도 있습니다. 그러나 바라건대, 이 장에서는 여전히 그 밖에 무엇이 있는지에 대한 감각을 제공할 것입니다.\n",
    "\n",
    "- 기술 스택에 대한 선택을 하는 것은 압도적일 수 있습니다. 유사한 경쟁 서비스를 제공하는 다양한 공급자가 있으며 그들이 제공하는 가격과 기능은 자주 변경됩니다. 이것은 절대적인 최고를 고르는 것을 거의 불가능한 운동으로 만듭니다. 경쟁 제공업체가 매우 다양하기 때문에 결정 피로도가 높아질 수 있습니다. 우리는 귀하가 해야 할 선택을 최소한으로 유지하기 위해 최선을 다할 것입니다. 사실, 우리는 한 단계 더 나아갈 것입니다. 이 책의 저자인 우리는 NLP 애플리케이션을 구축할 때 사용할 가장 좋아하는 도구를 선택할 것입니다!\n",
    "\n",
    "- 여기에 있는 목록은 포괄적이거나 확정적이지 않습니다(특정 순서나 순위도 아님). 여기에 나열한 도구는 저자인 우리가 유용하거나 대중적이거나 흥미롭다고 생각한 도구입니다. 무엇을 사용할지에 대한 결정은 항상 그렇듯이 귀하에게 달려 있습니다.\n",
    "\n",
    "- 현장에서 한 사람에게 효과가 있는 것이 당신에게는 효과가 없을 수 있습니다. 약간의 에누리하여 우리의 제안을 받아들이고 가장 적합한 것이 무엇인지 비판적으로 생각하십시오.\n",
    "\n",
    "- 결국 가장 중요한 것은 어떤 도구를 사용하느냐가 아니라 어떻게 사용하느냐이다. 사실, 많은 딥 러닝 프레임워크, 프로그래밍 언어 등이 종종 매우 유사하다는 것을 알게 될 것이며, 일단 다른 것을 배운 후에는 하나를 배우는 것이 그리 어렵지 않습니다.\n",
    "\n",
    "도구 정보를 몇 가지 범주로 나누고 각각 아래에 몇 가지를 나열했습니다. 각 섹션의 끝에서 The Motley Fool(https://www.fool.com)의 고전적인 스타일로 \"Ankur's Pick\" 및 \"Ajay's Pick\"이라는 레이블이 지정된 두 개의 특정 권장 사항을 찾을 수 있습니다. 다음은 우리가 개인적으로 좋아하는 것입니다.\n",
    "\n",
    "안쿠르의 선택  \n",
    "이들은 업계에서 안정적이고 대중적이며 잘 확장되는 도구에 중점을 두고 보다 생산 지향적인 경향이 있습니다.\n",
    "\n",
    "아제이의 추천  \n",
    "이들은 보다 실험적이고 연구 지향적일 것입니다. 이러한 도구는 신속한 실험 및 프로토타이핑을 위해 설계되었으며 최신 연구의 최첨단을 유지하는 데 도움이 됩니다.\n",
    "\n",
    "이 장을 마치면 NLP 응용 프로그램을 구축할 때 프로토타이핑과 생산 배포 모두에 사용할 수 있는 도구의 환경에 대해 잘 알게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Frameworks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥 러닝 프레임워크부터 시작하겠습니다. 이러한 프레임워크는 거의 모든 NLP(우리와 관련된)의 핵심 구성 요소이며 이 책 전체에서 광범위하게 사용할 것입니다. 대부분의 딥 러닝 프레임워크는 정확히 동일한 작업을 수행합니다. GPU에서 텐서 계산을 수행합니다.\n",
    "\n",
    "차이점은 다양한 고급 기능과 추상화를 구현하는 방식과 코드의 실제 성능을 제어하는 ​​덜 분명한 백엔드 구현을 관리하는 방식입니다.\n",
    "\n",
    "지난 10년 동안 여러 프레임워크가 단계적으로 등장했다가 사라졌습니다. Theano, Chainer, Lua, Torch 및 Caffe는 이전에 들었을 수도 있고 점점 덜 인기 있는 것입니다. 2020년 현재 이러한 작은 프레임워크는 대부분 구식이며 자세히 살펴볼 가치가 없다고 생각합니다.\n",
    "\n",
    "여러분에게 익숙하고 아마도 이미 사용해본 큰 것들은 PyTorch와 TensorFlow입니다. 이 두 프레임워크는 오늘날 가장 성공적인 두 기술 회사인 Facebook과 Google에서 각각 출시했습니다. 부분적으로는 개발자 커뮤니티가 딥 러닝 프레임워크를 채택하고 지원하기 때문입니다. 두 프레임워크 모두 몇 가지 공통점이 있습니다. 둘 다 오픈 소스이며 Python을 기본 프로그래밍 언어로 사용하는 인터페이스입니다. 그러나 둘 사이에는 몇 가지 차이점이 있으므로 자세히 강조하겠습니다.\n",
    "\n",
    "> PyTorch는 Torch 프레임워크를 기반으로 하고 TensorFlow는 Theano 프레임워크를 기반으로 합니다. Torch와 Theano는 인기가 떨어졌지만 그들의 파생 제품은 이제 딥 러닝 공간에서 가장 지배적입니다.\n",
    "\n",
    "그러나 블록에 새로운 아이들이 몇 명 있는데 아마도 익숙하지 않을 것입니다. Jax, Julia 및 TensorFlow용 Swift는 모두 강력한 새 기능, ​​훨씬 더 나은 성능/속도를 약속하며 지금까지 본 것과 상당히 크게 다릅니다. 안정성, 커뮤니티 및 하드웨어 지원 측면에서 여전히 PyTorch 및 TensorFlow만큼 구체화되지는 않았지만 많은 잠재력을 보여주고 좋은 개발 모멘텀을 가지고 있으므로 발끝을 담글 준비를 하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난 몇 년 동안 가장 빠르게 성장하고 있는 딥 러닝 프레임워크인 PyTorch부터 시작하겠습니다. Facebook의 AI Research lab(FAIR)에서 개발하여 2016년 10월 공개되었습니다. PyTorch는 이제 연구원들 사이에서 더 인기가 있다는 데 의견이 일치합니다.\n",
    "\n",
    "PyTorch의 핵심에는 torch.tensor 객체가 있습니다. numpy.ndarray와 거의 동일한 다차원 배열 유형으로, GPU 메모리에 상주할 수 있고 빠른 병렬 계산에 사용할 수 있습니다. 거의 모든 PyTorch는 행렬 곱셈, 컨볼루션 등과 같은 연산으로 이러한 텐서를 조작하기 위해 만들어졌습니다.\n",
    "\n",
    "PyTorch의 다른 큰 구성 요소는 autograd입니다. 이 기능은 신경망 훈련에 매우 유용한 PyTorch 텐서 연산을 사용할 때마다 그래디언트라는 수량을 자동으로 계산합니다.\n",
    "\n",
    "이 외에도 PyTorch를 설명하는 가장 쉬운 방법은 딥 러닝을 위한 편의 기능이 추가된 \"GPU의 NumPy\"라고 부르는 것입니다. 일반적으로 딥 러닝에는 GPU가 뛰어난 대형 텐서에서 유사한 계산을 반복적으로 수행하는 작업이 포함됩니다. NumPy는 CPU에서 계산을 수행하는데, 대부분의 경우 GPU에서 병렬로 저정밀 계산을 실행하는 것보다 훨씬 느립니다.\n",
    "\n",
    "대부분의 Python 프로그래머에게 PyTorch는 인터페이스가 NumPy와 매우 유사하기 때문에 자연스럽고 \"Pythonic\"하다고 느낄 것입니다. 이것은 PyTorch가 TensorFlow 이후에 출시되었다는 사실에도 불구하고 지난 몇 년 동안 인기가 계속해서 상승한 주된 이유 중 하나입니다.\n",
    "\n",
    "PyTorch와 TensorFlow 모두 분산 계산 기능을 제공하지만 PyTorch는 기본적으로 비동기 실행을 지원하기 때문에 학습 최적화가 더 좋습니다.\n",
    "\n",
    "딥 러닝 프레임워크의 작업은 텐서 데이터 구조에서 계산의 \"그래프\"를 실행하는 것으로 설명할 수 있습니다. PyTorch에서는 런타임에 그래프를 정의하므로 계획과 실행 사이를 쉽게 오갈 수 있습니다. 그래프를 명시적으로 컴파일하지 않고 작업을 즉시 평가하는 기능을 즉시 실행이라고 합니다.\n",
    "\n",
    "Eager Execution을 사용하면 더 빠르게 프로토타입을 만들고 새로운 유형의 아키텍처를 생성할 수 있지만 속도가 느려집니다. 이것을 컴파일된 언어와 해석된 언어의 차이로 생각하십시오.\n",
    "\n",
    "몇 년 전 TensorFlow가 정적 그래프를 사용했기 때문에 데이터를 밀어넣기 전에 먼저 전체 그래프를 정의해야 했기 때문에 이것은 큰 문제였습니다. 그러나 이제 두 프레임워크 모두 기본적으로 즉시 실행을 지원하며 이후 업계 표준으로 채택되었습니다.\n",
    "\n",
    "다음은 PyTorch 사용을 시작하기 전에 고려해야 할 항목별 목록입니다. 먼저 장점:\n",
    "\n",
    "- 배우기 쉽고 직관적입니다. 파이썬과 유사한 코딩\n",
    "- 동적 그래프\n",
    "- 빠른 실험 및 프로토타이핑에 탁월\n",
    "- 문서를 통한 읽기가 덜 필요합니다.\n",
    "- 다른 Python 패키지와의 통합 개선\n",
    "- 연구자 사이에서 빠르게 인기를 얻고 있음\n",
    "\n",
    "다음은 PyTorch 사용의 몇 가지 단점입니다.\n",
    "\n",
    "- 시각화를 위해 타사에 의존(예: Visdom)\n",
    "- 에지 장치 배포를 위한 덜 강력한 기본 시스템이 있음(API 서버 필요)\n",
    "\n",
    "이제 PyTorch의 급속한 성장에도 불구하고 오늘날 업계에서 가장 인기 있는 프레임워크인 TensorFlow와 PyTorch를 비교해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google 내부 사용을 위해 Google Brain 팀에서 개발한 TensorFlow 1.x는 2015년 말에 출시되었습니다. 업계에서 더 큰 사용자 기반을 보유하고 있지만 이는 더 일찍 출시되었고 많은 회사가 기존 TensorFlow 경험을 가지고 있기 때문일 수 있습니다. 그리고 레거시 코드. 같은 이유로 TensorFlow는 전반적으로 더 큰 커뮤니티 기반을 가지고 있습니다.\n",
    "\n",
    "일반적으로 우리는 TensorFlow의 1.x 버전을 권장하지 않습니다. API가 매우 부풀어 있고 일반적으로 PyTorch보다 더 장황하고 사용자 친화적이지 않기 때문입니다(실제로는 백엔드 문제로 인해 어떤 경우에는 더 느림).\n",
    "\n",
    "그러나 TensorFlow 2.0에서는 TensorFlow와 PyTorch 간의 차이가 좁혀졌습니다. TensorFlow는 이제 정적 그래프 대신 동적 그래프를 빌드하는 기능을 제공합니다. TensorFlow 2.0은 또한 매우 인기 있는 TensorFlow용 고급 API인 Keras를 완전히 통합합니다. TensorFlow 2.0은 프레임워크의 완전한 재설계로 많은 문제를 해결했지만 거의 모든 1.x 코드를 깨뜨리는 과감한 변경 사항에 대한 비판도 받았습니다.\n",
    "\n",
    "PyTorch와 비교할 때 TensorFlow는 뛰어난 시각화 기능(예: TensorBoard)을 내장하고 있으며 TensorFlow Lite를 사용하여 모바일 플랫폼을 더 잘 지원합니다(PyTorch Mobile에서는 변경 중임). 이 때문에 TensorFlow는 REST 클라이언트 API를 사용하는 TensorFlow Serving과 같은 도구 덕분에 생산 환경에서 배포하기가 더 쉽습니다.\n",
    "\n",
    "일반적으로 TensorFlow는 Python 프레임워크인 Though보다 훨씬 더 많은 것으로 구성됩니다. 이제 TensorFlow Lite, TensorFlow Extended, TensorFlow Serving, TensorFlow.js, TensorFlow.jl, TensorFlow Probability 등을 포함하여 셀 수 있는 것보다 더 많은 변형이 있습니다. 이것은 당신의 관점에 따라 도움이 되는 생태계가 될 수도 있고 다루기에 혼란스러운 골칫거리가 될 수도 있습니다.\n",
    "\n",
    "생산 준비가 된 애플리케이션을 구축할 준비가 되어 있고 TensorFlow 생태계에 구축된 기존 코드/인프라가 있을 수 있는 개발자에게 TensorFlow를 권장합니다.\n",
    "\n",
    "다음은 TensorFlow 사용을 시작하기 전에 고려해야 할 항목별 목록입니다. 첫째, 장점:\n",
    "\n",
    "- TensorFlow 2.0의 Keras를 사용하면 간단한 기본 제공 고급 API가 있습니다.\n",
    "- 이제 열망 모드 지원\n",
    "- 뛰어난 시각화(TensorBoard)\n",
    "- 프로덕션 준비 완료(TensorFlow Serving)\n",
    "- 훌륭한 모바일 지원\n",
    "- 대규모 개발자 커뮤니티 및 포괄적인 문서\n",
    "- 매우 큰 규모에서 더 나은 성능을 가집니다.\n",
    "- 업계의 지배적인 프레임워크\n",
    "\n",
    "다음은 TensorFlow 사용의 몇 가지 단점입니다.\n",
    "\n",
    "- 많은 사람들이 TensorFlow가 오늘날 우리가 사용하는 TensorFlow와 완전히 다르고 일반적으로 사용하기 훨씬 더 어려운 1.x 버전의 짐을 여전히 가지고 있다고 불평합니다.\n",
    "- 학습 곡선이 더 가파르고 때때로 새로운 언어처럼 느껴질 수 있습니다.\n",
    "\n",
    "PyTorch와 TensorFlow는 오늘날 사용 가능한 가장 인기 있는 두 가지 딥 러닝 프레임워크이지만, 결국 기존 프레임워크에 도전할 수 있는 빠르게 떠오르는 일부 새로운 프레임워크를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jax는 Google이 최근에 도입한 새로운 수치 컴퓨팅 라이브러리입니다. PyTorch에 의해 대중화된 \"NumPy on GPUs\"라는 아이디어를 완전히 새로운 수준으로 끌어 올립니다. 그 핵심에서 Jax는 표준 NumPy 및 Python 함수 위에 직접 autograd 기능(도함수를 명시적으로 지정하지 않고 연결된 함수의 그래디언트를 계산하는 기능, 딥 러닝 프레임워크에 매우 중요함)을 제공합니다. 이는 Jax의 autograd가 코드를 수정하지 않고도 루프, 조건문, 클로저 및 기타 기본 Python 구성을 처리할 수 있음을 의미합니다!\n",
    "\n",
    "그런데 Google이 TensorFlow와 매우 유사한 기능을 가진 새로운 라이브러리를 만드는 이유는 무엇입니까? 누가 알아? Jax 프로젝트는 TensorFlow에서 비롯된 XLA와 같은 구성 요소와 도구를 사용하지만 훨씬 더 깔끔하게 다시 작성한 것 같습니다. 결국 TensorFlow를 대체하게 될까요? 아마도. 시간만 잘 말해. 그러나 현재 우리가 가지고 있는 것은 가속기의 고성능에 초점을 맞추고 상용구 코드와 구문을 줄이는 데 초점을 맞춘 딥 러닝 프레임워크에 대한 유망한 새로운 방향을 나타내는 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 목록에 있는 다른 것들과 달리 julia는 단순한 프레임워크나 라이브러리가 아니라 완전히 새로운 프로그래밍 언어입니다. 제작자는 Python이 만들어질 때 성능 관점에서 많은 차선책 결정이 내려졌다는 우려를 표명했습니다. 결국 처음에는 사용하기 쉽고 다른 모든 것은 두 번째로 설계되었습니다.\n",
    "\n",
    "그러나 오늘날 우리는 Python 도구를 사용하여 대규모 데이터 세트를 관리하고 복잡한 과학 시뮬레이션을 실행하며 수십억 개의 매개변수로 심층 신경망을 교육하고 있습니다. 이것은 단순함을 위해 성능을 희생하는 언어로 수행되어야 하는 것으로 보이지 않습니다.\n",
    "\n",
    "julia는 처음부터 수치 및 과학 계산을 위해 설계되었습니다. Python에는 서버 백엔드, 데이터베이스 및 스크립팅을 포함하여 많은 사용 사례가 있지만 Julia는 Python 프로그래머가 사용하는 전통적인 \"데이터 과학 스택\"(예: NumPy, pandas, matplotlib, SciPy 등)에 중점을 둡니다.\n",
    "\n",
    "이 책에서 Julia를 광범위하게 다루지는 않겠지만 직접 확인하는 것이 좋습니다.\n",
    "\n",
    "> Honoralbe 언급: TensorFlow용 Swift\n",
    "> Swift for TensorFlow(때때로 S4TF로 약칭됨)는 julia가 수행하는 것과 유사한 문제인 Python의 근본적인 한계를 해결하려고 시도했습니다.\n",
    "\n",
    "> 이 프로젝트는 일반적으로 미분 가능 프로그래밍, 컴파일러 및 수치 컴퓨팅 분야에 귀중한 기여를 했지만 안타깝게도 2021년에 개발이 중단되었습니다. S4TF 팀의 노력에 감사드리며 이제 Swift 프로그래밍에 여러 가지 업스트림 변경 사항을 도입했습니다. 언어 자체; 그 예는 차별화 가능한 주류 프로그래밍 언어를 구축하려는 다른 프로젝트에 영감을 주었습니다.\n",
    "\n",
    "더 이상 고민하지 않고 개인적인 선택은 다음과 같습니다.\n",
    "안쿠르의 선택  \n",
    "이것은 나에게 매우 어려운 선택입니다. 한편으로 저는 PyTorch가 \"Pythonic\"이라는 점을 감안할 때 PyTorch에서 프로토타입을 만드는 것을 좋아합니다. 반면에 TensorFlow는 업계에서 매우 확고하게 자리잡았기 때문에 TensorFlow에서 학습하고 개발하는 데 많은 투자를 하지 않는 것이 어렵습니다. 제가 추천하는 것은 PyTorch의 용이성과 단순성을 선호하기 때문에 TensorFlow를 배우는 것입니다. 저는 개인적으로 이것이 최고의 선택입니다.\n",
    "아제이의 선택  \n",
    "제가 선택한 딥 러닝 프레임워크는 PyTorch입니다. 일부 새로운 기능에 완전히 빠져버렸고 딥 러닝 프레임워크가 다른 프로그래밍 언어로 확장되는 것을 기다릴 수는 없지만 현재로서는 PyTorch가 여전히 가장 신뢰할 수 있는 솔루션인 것 같습니다. 그것은 연구를 위한 훌륭한 도구이며 많은 최신 학술 문헌이 PyTorch에서 구현되어 새로운 아키텍처, 옵티마이저 등을 매우 쉽게 조정하고 테스트할 수 있습니다.\n",
    "다음으로 딥 러닝 교육 요구 사항을 위한 시각화 및 실험 추적 소프트웨어에 대해 논의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Experiment Tracking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종종 한 모델, 그 다음 다른 모델, 그 다음 모델을 훈련하기 시작하고 \"잠깐만, 내가 이걸 시도하면...\"\n",
    "\n",
    "학습 파이프라인을 설정하고 나면 여러 실험을 신속하게, 심지어 동시에 실행할 수도 있습니다. 이 단계에서 딥 러닝 실무자로서의 대부분의 노력은 코드 작성이 아니라 모델, 데이터 또는 교육 루프의 몇 가지 주요 구성 요소를 조정하는 데 사용됩니다.\n",
    "\n",
    "이 빠른 실험 단계를 시작할 때 최상의 솔루션을 찾기 위해 수백 번의 실험을 실행해야 할 수도 있습니다. 실험을 시각화하고 추적하는 소프트웨어가 없으면 어떤 실험이 가장 유망했고 어떤 방향이 더 추구할 가치가 있는지 추적하기가 어려울 것입니다. 좋은 시각화 소프트웨어 없이는 이러한 모델을 디버깅하는 것도 어렵고 시간이 많이 걸립니다. 또한 오늘날 대부분의 기계 학습은 매우 협력적이므로 중복 실험과 같은 문제를 피하기 위해 팀 내에서 작업을 추적하고 다른 사람과 진행 상황을 공유하는 소프트웨어가 필요합니다.\n",
    "\n",
    "실험을 추적하고, 성능을 모니터링하고, 실험의 버전을 제어하고, 나머지 팀과 결과를 공유하는 데 도움이 되는 도구가 바로 이 섹션의 전부입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard는 TensorFlow의 기본 제공 시각화 소프트웨어입니다. 오픈 소스이며 무료이며 매우 큰 사용자 커뮤니티가 있습니다. 이를 통해 그래프를 시각화하고, 손실 및 정확도와 같은 지표를 추적 및 시각화하고, 시간 경과에 따른 가중치 및 편향의 히스토그램을 보고, 저차원 공간에 임베딩을 투영하고, 이미지, 텍스트 및 오디오 데이터를 표시할 수 있습니다.\n",
    "\n",
    "TensorBoard를 사용하면 여러 실험을 실행하고 어떤 실험이 더 좋은/나쁜 성능으로 이어지는지 추적할 수 있습니다. 이는 예를 들어 하이퍼파라미터를 보다 쉽게 ​​조정하여 모델 성능을 최적화하는 데 도움이 됩니다. 또한 TensorBoard를 사용하면 기계 학습 모델의 문제를 더 쉽게 해결할 수 있습니다.\n",
    "\n",
    "TensorBoard의 최신 버전인 Tensorboard.dev를 사용하면 실험을 호스팅하고 추적하고 다른 사람과 공유할 수도 있습니다. 이는 팀 내부 및 팀 간의 협업에 특히 유용합니다. TensorBoard.dev 이전에는 공동 작업을 위해 TensorBoard의 스크린샷을 다른 사람에게 제출해야 했습니다.\n",
    "\n",
    "TensorBoard는 TensorFlow를 위한 훌륭한 기본 제공 솔루션이지만 공간의 다른 플레이어가 제공하는 많은 협업 기능이 부족합니다. TensorBoard의 가장 큰 장점은 PyTorch가 현재 제공하지 않는 공식 자사 내장 도구라는 사실에 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights & Biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 기계 학습 실무자는 스프레드시트로 ML 실험을 추적하는 데 의존합니다. 20세기에 속하지 않는 한 이 접근 방식은 업계에서 취약하고 확장할 수 없습니다. 훌륭한 딥 러닝 시각화 및 실험 추적 소프트웨어에 대한 필요성을 감안할 때 Weights & Biases와 같은 회사가 생겨났습니다.\n",
    "\n",
    "2017년에 설립된 Weights & Biases를 통해 팀은 단 몇 줄의 코드만으로 ML 실험을 추적하고, 모델 성능을 시각화 및 최적화하고, 데이터 세트 및 모델의 버전 관리를 유지할 수 있습니다. TensorBoard는 개인이 독립적으로 실험할 수 있도록 설계되었지만 Weights & Biases는 협업 팀을 염두에 두고 설계되었습니다.\n",
    "\n",
    "Weights & Biases는 하이퍼파라미터, 메트릭 등을 자동으로 추적하고 클라우드에 기록합니다. 그런 다음 실시간으로 업데이트되는 대화형 대시보드를 통해 결과를 시각화할 수 있습니다. 플롯, 샘플 예측, 오디오, 비디오, 3D 모델 및 원시 HTML을 포함하여 관심이 있는 거의 모든 것을 기록할 수 있습니다. 이 도구는 또한 태그, 필터링, 그룹화 및 다양한 형식으로 내보내는 기능을 제공하여 실험을 체계적으로 구성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neptune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights & Biases와 마찬가지로 Neptune을 사용하면 실험을 추적하고 팀을 위한 작업을 구성할 수 있습니다. Neptune의 가장 좋은 점은 여러 프레임워크에 쉽게 연결할 수 있고 매우 가벼운 도구라는 점입니다. 노트북 환경(예: Jupyter, JpyterLab 및 Google Colab)에서 매우 쉽게 작동합니다.\n",
    "\n",
    " Neptune은 모든 mdoel 교육(클래식 머신 러닝, 딥 러닝, 강화 학습 등)을 위한 경량 실험 관리 도구를 원하는 사용자에게 가장 적합합니다. 또한 뛰어난 노트북 추적(Jupyter 및 JupyterLab용)을 제공합니다. 대부분의 기계 학습 작업을 노트북에서 수행하는 경우 Neptune은 실험 추적을 위한 최고의 경쟁자입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comet은 딥 러닝뿐만 아니라 모든 모델 교육에 적합합니다. 또한 다른 실험 추적 소프트웨어 플랫폼에는 없는 메타 기계 학습 기능(예: AutoML)을 제공합니다. Weights & Biases와 마찬가지로 Comet은 업계 실무자에게 권장하는 강력한 소프트웨어입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오늘날 최고의 데이터 사이언스 플랫폼 중 하나인 Databricks의 제작자가 2018년에 개발한 MLflow는 기계 학습 실험을 추적하고 모델을 등록하고 모델을 배포하는 무료 오픈 소스 기술입니다. 즉, MLflow는 프로토타이핑에서 배포까지 전체 기계 학습 수명 주기를 관리하는 데 도움이 됩니다. MLflow는 많은 실험을 추적해야 하는 개인에게 도움이 되지만 실제로 팀과 함께 빛을 발합니다. 팀은 동료의 결과를 재현하고 이전 실험과 다른 사람들이 이미 수행한 모델링을 활용하여 더 나은 협업을 할 수 있습니다. 모델이 중앙 리포지토리에 등록되기 때문에 MLflow는 프로덕션에 있는 mdoel과 액세스 방법을 팀 구성원에게 명확하게 알려줍니다.\n",
    "\n",
    "MLflow는 전체 기계 학습 수명 주기를 관리하기 때문에 TensorBoard 및 Weights & Biases와 다릅니다. 즉, 단순한 실험 추적 소프트웨어 그 이상입니다. 그러나 가벼운 실험 추적 기능이 있습니다.\n",
    "\n",
    "MLflow의 주요 단점은 TensorBoard, Weights & Biases, Comet 및 Neptune이 제공하는 시각화 기능이 부족하다는 것입니다. 실제로 MLflow는 사용자 인터페이스가 매우 제한적입니다. 또한 MLflow는 데이터브릭과 함께 사용할 때 가장 잘 작동합니다. 독립형 기술로서 사용자 관리와 같이 기업에 필요한 많은 기능이 부족합니다.\n",
    "\n",
    "11장에서는 MLflow를 다시 살펴보고 가장 빛나는 부분인 모델 저장소와 모델 배포를 보여줍니다.\n",
    "\n",
    "우리의 선택은 다음과 같습니다.\n",
    "안쿠르의 선택  \n",
    "여기서 가장 좋은 단일 선택은 Weights & Biases입니다. 그곳의 팀은 기계 학습 작업에 도움이 되는 소프트웨어를 개발하는 방법을 진정으로 이해하고 있습니다. Weights & Biases의 설립자는 이전에 Figure Eight(이전 CrowdFlower로 알려짐)라는 매우 유명하고 성공적인 데이터 주석 회사를 설립했으며, 저는 과거에 이 회사를 사용했고 이후 Appen에 인수되었습니다. 더 나은 프로세스로 실험 프로세스를 보다 체계적으로 만들고 싶다면 Weights & Biases가 솔루션입니다. Weights & Biases는 또한 11장에서 사용하는 Databricks를 포함하여 거의 모든 주요 데이터 과학 프레임워크 및 플랫폼과 잘 통합됩니다.\n",
    "\n",
    "아제이의 선택  \n",
    "나는 다른 어떤 것보다 Weights & Biases를 훨씬 더 많이 사용해 왔기 때문에 여기에서 편향되어 있습니다. 하지만 그것은 내가 시도한 첫 번째 도구이고 내가 하는 일에 완벽하다는 것을 알았기 때문입니다. 내가 보기에 Weights & Biases는 코드 공간에서 아이디어 공간으로 작업하는 데 정말 도움이 됩니다. 모든 모델과 결과를 한 곳에 모아두면 딥 러닝 실무자로서의 생산성이 정말 향상됩니다.\n",
    "\n",
    "이제 학습 프로세스에 도움이 될 수 있는 자동화된 기계 학습으로 이동하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신 러닝은 더욱 성숙해지고 수요가 증가하고 있습니다. 그 결과 최근 몇 년 동안 자동화 머신러닝(AutoML)에 특화된 스타트업이 데이터 사이언스 커뮤니티의 화두가 됐다. AutoML의 현재 주요 플레이어와 이들이 NLP 애플리케이션 구축에 어떻게 도움이 될 수 있는지 살펴보겠습니다.\n",
    "\n",
    "표준 기계 학습 파이프라인에는 다음 단계가 포함됩니다.\n",
    "\n",
    "1. 데이터를 가져옵니다.\n",
    "2. 데이터 전처리(예: 누락된 값 및 이상값 처리, 데이터 유형 확인 및 변환 등).\n",
    "3. 기능 스케일링, 엔지니어링 및 선택을 수행합니다.\n",
    "4. 데이터 구조화(예: 교육, 교차 검증 및 테스트 세트 생성 등).\n",
    "5. 평가 메트릭을 정의하고 다양한 하이퍼파라미터로 모델을 선택하고 테스트합니다.\n",
    "6. 알고리즘을 설정하고 다양한 하이퍼파라미터로 모델을 선택하고 테스트합니다.\n",
    "7. 생산에 배포할 모델을 선택합니다.\n",
    "8. 코드를 리팩터링하고, 테스트를 작성하고, 프로덕션으로 푸시합니다.\n",
    "9. 프로덕션에서 모델을 모니터링하고 유지 관리합니다.\n",
    "10. 실제 결과를 수집하고 필요에 따라 모델을 재교육합니다.\n",
    "\n",
    "AutoML은 어느 정도 자동화된 기계 학습으로 인간 코더의 노력을 줄여줍니다. AutoML에는 다음이 포함될 수 있습니다.\n",
    "- 자동화된 데이터 준비(예: 결측값 대치, 기능 스케일링, 기능 선택 등)\n",
    "- 자동화된 그리드 검색 및 하이퍼파라미터 최적화\n",
    "- 여러 알고리즘의 자동 평가\n",
    "- 모델의 자동화된 앙상블(예: 앙상블 선택 및 스태킹)\n",
    "\n",
    "AutoML은 표준 기계 학습 파이프라인의 일부를 자동화함으로써 데이터 전처리, 기능 엔지니어링, 모델 배포 및 유지 관리 작업에 사용할 시간을 확보합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O.ai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2012년에 설립된 H2O.ai는 프로그래머가 ML 애플리케이션을 매우 빠르게 구축할 수 있도록 지원하는 오픈 소스 기계 학습 플랫폼입니다. 2021년 초 현재 1억 5,100만 달러를 모금하여 자금이 매우 풍부합니다. 고전적인 머신 러닝(예: 랜덤 포레스트, 그래디언트 부스팅, 일반화된 선형 모델 등)과 딥 러닝을 모두 지원합니다. 플랫폼의 핵심은 최고의 모델의 순위표를 생성하기 위해 여러 하이퍼파라미터로 여러 알고리즘을 실행하는 기능입니다. 즉, 알고리즘 선택 및 하이퍼파라미터 최적화와 같은 작업을 수행하여 문제에 가장 적합한 모델을 찾는 데 도움이 됩니다.\n",
    "\n",
    "Python과 R을 모두 지원하는 H2o는 강력합니다. 또한 사용자가 몇 번의 버튼 클릭으로 실험을 실행할 수 있도록 코드 없는 그래픽 노트북 기반 대화형 UI를 제공합니다. UI는 H2O Flow로 알려져 있습니다. H2O의 AutoML은 개별 모델을 자동으로 앙상블하여 전반적인 성능을 향상시킵니다. H2O는 빅 데이터 문제를 위해 구축되어 분산된 메모리 내 머신 러닝을 지원합니다.\n",
    "\n",
    "NLP를 일부 지원합니다. H2o는 TFIDF, CNN 및 GRU와 같은 기술을 사용하여 텍스트 문자열을 기능으로 변환할 수 있습니다. 이러한 기능은 기존 머신 러닝 또는 딥 러닝 알고리즘에 입력됩니다.\n",
    "\n",
    "H2o는 데이터 과학자가 모델 교육 및 평가 속도를 높이는 데 유용한 플랫폼이지만 숙련된 데이터 과학자와 ML 엔지니어는 자신이 선택한 실험 추적 소프트웨어와 결합된 PyTorch 또는 TensorFlow와 같은 딥 러닝 프레임워크를 활용하여 모델을 더 잘 제어하는 ​​것을 선호합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataiku"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataiku는 또 다른 주요 데이터 과학 플랫폼입니다. 2013년에 설립되었으며 2021년 초 현재 2억 4,700만 달러를 모금했습니다. Dataiku는 조직 내에서 여러 데이터 플레이어(예: 데이터 과학자, 데이터 분석가, 데이터 엔지니어 등)를 통합하는 협업 데이터 과학 소프트웨어 플랫폼입니다.\n",
    "\n",
    "H2O는 엄격하게 기계 학습 플랫폼(여러 ML 모델을 빠르게 교육하고 평가하기 위한)인 반면 Dataiku는 데이터 탐색, 기능 엔지니어링, 모델 구축, 데이터 분석, 통찰력 및 모델 배포를 포함하여 보다 일반화된 데이터 과학 작업을 위해 구축되었습니다. H2O와 마찬가지로 Dataiku는 코드가 없고 클릭하기 쉬운 UI로 코더와 비코더를 모두 지원합니다.\n",
    "\n",
    "Dataiku는 개발에서 테스트, 프리프로덕션, 프로덕션으로 매우 빠르게 이동할 수 있는 좋은 방법입니다. 필요에 따라 데이터 워크플로 생성, 데이터 파이프라인 자동화, 성능 모니터링, 모델 버전 관리, 이전 버전으로 롤백과 같은 많은 오버헤드를 관리합니다. 또한 거버넌스, 보안 및 모니터링과 같은 기타 까다로운 요소를 관리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataRobot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 분야에서 자금이 풍부한 또 다른 플레이어는 DataRobot으로, 2012년 설립된 지 불과 9년 만인 2021년 초 현재 7억 5,100만 달러를 모금했습니다. Dataiku와 마찬가지로 DataRobot은 모델 구축, 배포 및 관리. 이는 H2O가 제공하는 AutoML 기능과 Dataiku의 전체 엔드 투 엔드 데이터 사이언스 및 엔지니어링 기능이 훌륭하게 결합된 것입니다.\n",
    "\n",
    "DataRobot은 오늘날 시장에서 단일 최고의 데이터 과학 소프트웨어 플랫폼이라고 생각하는 것을 구축하기 위해 몇 가지 놀라운 인수를 했습니다. AutoML뿐만 아니라 MLOps도 포함합니다(2019년 ParallelM 인수를 통해). 이를 통해 프로덕션 환경에서 기계 학습 모델을 배포, 모니터링, 관리 및 통제할 수 있습니다. 온프레미스 또는 클라우드 공급자(예: Amazon Web Services(AWS), Google Cloud Platform(GCP) 및 Azure)에서 Kubernetes 및 Spark와 같은 모든 최신 프로덕션 인프라를 지원합니다. ML 애플리케이션을 프로덕션으로 가져간 후에는 모델에 대한 작업의 실시간 모니터링 및 경고 및 감사를 지원합니다.\n",
    "\n",
    "즉, 일련의 인수가 주어진 DataRobot입니다. 엔드투엔드 데이터 과학 및 기계 학습 파이프라인을 지원하는 가장 강력한 기능을 갖추고 있습니다.\n",
    "\n",
    "우리의 선택은 다음과 같습니다.\n",
    "\n",
    "안쿠르의 선택  \n",
    "내 최고의 선택은 일련의 인수를 고려할 때 DataRobot입니다. 엔드투엔드 데이터 사이언스와 기계 학습 파이프라인을 지원하는 가장 강력한 기능을 갖추고 있습니다.\n",
    "\n",
    "아제이의 선택  \n",
    "나는 주로 내 자신의 모델을 처음부터 훈련하기 때문에 개인적으로 AutoML을 사용한 적이 없습니다. 여기에서 선택하지 마십시오!\n",
    "\n",
    "다음 섹션에서는 기계 학습 모델을 교육하기 위해 컴퓨팅 리소스에 액세스하는 옵션을 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Infrastructure and Compute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥 러닝에서 가장 짜증나고 비용이 많이 드는 부분은 컴퓨팅에 대한 액세스 권한을 얻는 것입니다.\n",
    "\n",
    "오늘날 진지한 딥 러닝을 하고 싶다면 Nvidia GPU가 필요할 것입니다. 모든 딥 러닝 프레임워크는 주로 Nvidia 독점 기술인 CUDA를 대상으로 하기 때문에 Nvidia는 안정적으로 사용할 수 있는 유일한 브랜드입니다. 미래에는 컴퓨팅을 위한 다른 경쟁 옵션이 많이 있기를 바라지만 현재는 그렇지 않습니다.\n",
    "\n",
    "워크스테이션용 자체 그래픽 카드에 투자하거나 GPU가 설정된 클라우드 인스턴스에 연결할 수 있습니다. 초보자라면 자체 GPU 비용을 선불로 지불하는 것보다 저렴한 클라우드 서비스로 시작하는 것이 더 나을 것입니다. 워크스테이션 설정에는 브라우저에서 클릭만으로 Jupyter 노트북에 연결하는 것보다 훨씬 더 많은 노력이 필요합니다. 그러나 결국 매일 많은 실험을 실행하고 컴퓨팅 시간에 대해 주머니에서 돈을 지불하게 되면 자체 GPU를 사용하여 비용을 절약할 수 있습니다.\n",
    "\n",
    "3대 클라우드 제공업체인 AWS, GCP 및 Microsoft Azure는 모두 훈련을 위한 최신 GPU 하드웨어를 제공합니다. 대부분의 경우 어떤 서비스를 사용할지에 대한 결정은 비용으로 귀결됩니다. 이는 시간이 지남에 따라 많이 달라지므로 최신 리소스를 위해 GitHub 사용자 zszazi는 향후 몇 년 동안 볼 수 있는 대부분의 클라우드 서비스 제공을 비교하는 훌륭한 표(https://oreil.ly/q8wLz)를 작성했습니다.\n",
    "\n",
    "이 섹션에서는 교육 인프라 공간의 새로운 플레이어를 소개하고 이들이 딥 러닝 엔지니어에게 제공하는 고유한 기능을 설명하고 평소와 같이 선택 사항을 알려줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaperSpace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014년에 설립된 Paperspace는 틈새 기계 학습 중심의 클라우드 컴퓨팅 회사입니다. GPU를 사용하여 기계 학습 모델을 개발하고 배포하려는 개인과 팀에 ML 개발 플랫폼을 제공합니다. Paperspace는 GPU 기반 머신 러닝 애플리케이션 구축에만 집중하는 팀에게 적합한 선택입니다. 선불 비용이 매우 비싸고 상당한 하드웨어 설정이 필요한 맞춤형 GPU 워크스테이션을 구축하는 대신, 데이터 과학자는 필요에 따라 클라우드 기반 GPU를 활용하고 사용한 만큼 비용을 지불할 수 있습니다(일반적으로 시간당).\n",
    "\n",
    "AWS, Azure 및 GCP와 비교할 때 Paperspace는 보다 투명한 가격으로 보다 직관적인 제품 세트를 제공합니다. 이를 통해 팀은 올바른 GPU 세트로 가상 머신을 가동하고, 모든 프레임워크(TensorFlow 및 PyTorch 포함)를 사용하여 기계 학습 모델을 훈련하고, 모델 버전을 지정하고, 팀 내에서 코드를 공유하고, 훈련 및 추론 작업을 확장하고, 모델을 만들 수 있습니다. API를 통해 사용할 수 있습니다.\n",
    "\n",
    "AWS에서 인프라를 설정하는 데 1시간 이상 소요하는 대신 Paperspace를 사용하여 몇 분 안에 기계 학습 모델을 교육하도록 인프라를 설정할 수 있습니다.\n",
    "\n",
    "Paperspace의 핵심 제품은 Paperspace Gradient입니다. 머신 러닝 모델을 개발하고 배포하는 데 필요한 모든 인프라를 제공합니다. 몇 번의 클릭만으로 클라우드 환경을 설정하고, 데이터를 로드 및 탐색하고, Jupyter Notebook을 통해 모델을 개발하고(단일 인스턴스를 활용하거나 분산 교육으로 확장할 수 있는 옵션도 있음), 모델 성능을 모니터링하고, 요청 볼륨에 따라 확장할 수 있는 기능이 있는 GPU 또는 CPU를 사용하여 API 엔드포인트로 모델링합니다. 부팅을 위해 Gradient는 GitHub와의 지속적인 통합 서비스도 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FloydHub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FloydHub는 Paperspace와 유사하며 데이터 과학자에게 기계 학습 모델을 교육, 테스트 및 배포할 수 있는 관리형 클라우드 플랫폼을 제공합니다. Paperspace와 마찬가지로 FloydHub는 멋지게 패키지된 제품으로 클라우드 인프라를 제공하여 데이터 과학자가 작업을 수행하는 데 필요한 인프라 관리에 대해 걱정할 필요 없이 코딩할 수 있도록 합니다. 여기에는 DevOps도 포함됩니다(예: 인프라 프로비저닝, 작업 오케스트레이션, 로깅 관리, 보안 등). FloydHub와 Paperspace 모두 실험 추적 소프트웨어를 제공하므로 작업을 추적, 구성 및 공유할 수 있습니다.\n",
    "\n",
    "FloydHub의 핵심 제품은 FloydHub 작업 공간으로 JupyterLab에서 제공하며 기능 면에서 Paperspace Gradient와 유사합니다.\n",
    "\n",
    "AWS, Azure 및 GCP와 같은 기존 플레이어와 비교할 때 Paperspace 및 FloydHub는 더 새롭고 훨씬 작은 커뮤니티를 지원합니다. 결과적으로 클라우드 컴퓨팅 대기업에 비해 커뮤니티에서 후원하는 문서 및 지원이 적습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계 학습 모델 훈련을 위한 지금까지 가장 간단하고 저렴한(무료!) 클라우드 서비스는 Google에서 호스팅하는 무료 클라우드 서비스인 Google Colab(\"Colaboratory\")입니다. Google Colab은 구성이 필요하지 않고 GPU에 대한 무료 액세스를 제공하며 매우 쉽게 공유할 수 있습니다. 핵심적으로 Colab 노트북은 Google의 인스턴스를 사용하여 모델 학습에 필요한 컴퓨팅을 수행하는 온라인 클라우드 기반 Jupyter 노트북입니다.\n",
    "\n",
    "Colab 노트북은 모두 Google 드라이브 계정에 저장되며 노트북 환경을 통해 사용자는 Google 드라이브, GitHub 및 기타 여러 소스의 데이터 및 코드에 액세스할 수 있습니다. Colab에는 NumPy, pandas, TensorFlow, PyTorch, Scilit-learn 등 데이터 과학 및 기계 학습에 사용되는 많은 주요 Python 라이브러리가 사전 설치되어 있습니다. 새 라이브러리를 설치하는 것도 매우 쉽습니다. Colab은 노트북 환경에서 직접 셸 명령을 허용합니다.\n",
    "\n",
    "몇 가지 단점이 있습니다. Colab은 CPU에서 최대 24시간, GPU에서 최대 12시간 동안 코드를 실행할 수 있습니다. 이 기간이 지나면 노트북이 VM에서 연결 해제되어 진행 중인 교육이 중단됩니다. 그러나 무제한 기간 동안 로컬 런타임과 훈련을 연결할 수 있는 옵션이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Kernels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google 소유의 온라인 기계 학습 경쟁 플랫폼인 Kaggle은 사용자가 데이터 세트를 찾아 게시하고, 모델을 구축하고, 작업을 공유할 수 있는 자체 Jupyter Notebook 환경을 제공합니다. Kaggle 커널로 알려져 있습니다. Kaggle 커널을 사용하면 사용자가 코드를 작성하고 공유하여 작업을 재현 가능하게 만들고 공동 작업자를 초대하여 진행 중인 프로젝트에서 공동 작업을 수행할 수 있습니다. Kaggle 커널은 코드, 주석, 환경 변수, 필수 입력 파일 및 출력을 저장합니다. 이 모든 것은 Docker 컨테이너에서 실행됩니다.\n",
    "\n",
    "Docker 컨테이너는 격리된 환경에서 애플리케이션을 실행하는 데 필요한 모든 종속성 및 코드의 자체 포함 패키지로, 실행되는 시스템에 관계없이 소프트웨어가 균일하게 작동하도록 합니다.\n",
    "\n",
    "Docker 컨테이너에는 가장 일반적인 데이터 과학 라이브러리와 프로젝트별 데이터 세트가 미리 로드되어 있습니다. 커널은 웹을 통해 이 Docker 컨테이너에 연결되어 사용자가 로컬 컴퓨터에서 설정하지 않고도 웹 브라우저를 통해 데이터 과학 및 기계 학습 작업을 빠르게 수행할 수 있습니다. 두 가지 커널 유형이 있습니다. 처음부터 끝까지 전체 코드를 실행하는 스크립트 또는 데이터 탐색 및 통찰력을 지원하는 노트북을 만들 수 있습니다.\n",
    "\n",
    "Google Colab에 비해 Kaggle Kernels는 더 느리고 더 짧은 실행 시간을 제공합니다(GPU를 사용하는 Google Colab의 총 실행 시간은 12시간에 비해 총 실행 시간은 9시간). 학생, 학자, 연구원, 데이터 과학 애호가 및 데이터 과학 경쟁자에게 Kaggle Kernels는 머신 러닝에 대해 자세히 배우고, 모델을 개발 및 공유하고, 더 광범위한 데이터 과학 커뮤니티에 참여할 수 있는 좋은 방법이지만 실행 가능한 옵션은 아닙니다. 엔터프라이즈에서 모델을 교육합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda GPU Cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 클라우드 공간의 또 다른 신규 사용자는 Lambda Labs입니다. Lambda Labs는 딥 러닝 워크스테이션 및 하드웨어(처음부터 직접 구축하는 데 관심이 없다면 고려해 볼 가치가 있음)로 가장 잘 알려져 있지만 최근에는 Lambda GPU 클라우드도 제공하기 시작했습니다. 이것은 계속 주시해야 할 플레이어이지만 아직 여기에 있는 다른 컴퓨팅 공급자만큼 강력하고 완전한 솔루션을 제공하지는 않습니다.\n",
    "\n",
    "우리의 선택은 다음과 같습니다.\n",
    "학생과 가격에 민감한 개발자에게 Google Colab은 무료이고 사용하기 쉽기 때문에 시작하기에 가장 좋은 곳입니다. 버튼을 한 번만 클릭하면 모든 Gmail 사용자가 사용할 수 있습니다.\n",
    "\n",
    "보통의 회사가 아닌 개발자의 경우 Paperspace 또는 FloydHub가 가장 좋은 옵션입니다. 사용하기 쉽고 직관적이며 유지 관리에 IT 오버헤드가 필요하지 않습니다.\n",
    "\n",
    "보통 또는 무거운 개발자(예: 전문가), 특히 엔터프라이즈의 경우 AWS, Azure 및 GCP가 최상의 옵션입니다. 이러한 회사는 IT 조직에서 기계 학습 작업을 지원하는 데 필요한 다양한 클라우드 서비스를 제공합니다. 회사가 초기 단계인 경우 스타트업 할인 프로그램에 적합할 수 있습니다. 회사가 잘 구축되어 있다면 장기 계약에 대한 할인을 협상할 수 있어야 합니다.\n",
    "\n",
    "다음은 개별 선택입니다.\n",
    "\n",
    "안쿠르의 선택  \n",
    "AWS, GCP 또는 Azure와 이미 밀접하게 연결된 대규모 조직에서 근무하지 않는 한 UI/UX 친화적인 플랫폼을 통해 클라우드에서 GPU를 활용하는 것이 좋습니다. 이것이 오늘날 Paperspace가 제가 가장 좋아하는 선택인 이유입니다. GPU를 가동하고, 여러 ML 모델을 병렬로 교육한 다음 완료 후 GPU를 가동 중지하는 것은 쉽습니다. 또한 Paperspace를 사용하여 모델을 API로 사용할 수 있도록 할 수 있습니다. AWS, GCP 및 Azure에서 제공하는 서비스에 비해 사용하기가 더 쉽습니다.\n",
    "\n",
    "아제이의 선택  \n",
    "많은 클라우드 서비스를 시도하고 딥 러닝을 위해 여러 워크스테이션을 설정했지만 현재는 Colab과 대학에서 제공하는 컴퓨팅 클러스터를 주로 사용하고 있습니다. 물론 모든 사람이 컴퓨팅 클러스터에 액세스할 수 있는 것은 아니므로 일반적으로 Colab을 권장합니다. 무료라는 명백한 이점 외에도 Colab에 대해 제가 좋아하는 점은 jupyter 노트북에 들어가는 것이 얼마나 쉬운지입니다. 사실 저에게는 Colab 인스턴스를 실행하는 것이 로컬 Jupyter Notebook 서버를 실행하는 것보다 빠릅니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge / On-Device Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로덕션 환경에서 모델을 배포할 때 클라우드 또는 온디바이스에서 추론을 실행할 수 있는 두 가지 방법이 있습니다. 대부분의 경우 장점/단점은 예상한 것입니다.\n",
    "\n",
    "대부분의 경우 클라우드에서 인터렌스를 실행하면 클라우드 GPU를 활용하고 원하는 방식으로 추론을 실행할 수 있으므로 최종 사용자에게 더 빠른 경험을 제공합니다. 또한 API를 통해 액세스할 수 있는 하나의 통합 백엔드를 사용할 수 있으므로 여러 플랫폼, 장치 및 하드웨어 구성 지원에 대해 걱정할 필요가 없습니다.\n",
    "\n",
    "그러나 오프라인 또는 온디바이스 추론을 매력적으로 만드는 것은 사용자가 모델을 사용하기 위해 인터넷 연결이 필요하지 않다는 것입니다. 이는 애플리케이션에 따라 큰 고려 사항이 될 수 있습니다. 또한 컴퓨팅을 사용자의 장치로 오프로드하면 특히 GPU 인스턴스가 기존 웹 서버보다 훨씬 더 비싸기 때문에 클라우드 서비스 비용을 많이 절약할 수 있습니다.\n",
    "\n",
    "먼저 온디바이스 인터렌스를 비교한 다음 주요 클라우드 서비스 공급자를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONNX(Open Neural Network Exchange)는 여러 장치 및 플랫폼에서 추론을 처리하는 가장 중요한 프로젝트입니다. 범위가 제한된 라이브러리, 프레임워크 등 대신 ONNX는 모든 종류의 추론 엔진, 프로그래밍 언어, 장치 등에서 실행할 수 있는 기계 학습 모델을 저장하기 위한 새로운 형식을 제시합니다. ONNX 모델이 백엔드인 \"프론트엔드\" 및 \"백엔드\". ONNX는 모든 주요 딥 러닝 프레임워크를 지원하며 브라우저, 모바일 장치 등에서 ONNX 모델을 실행할 수 있도록 하는 널리 사용되는 클라이언트 구현이 많이 있습니다.\n",
    "\n",
    "그러나 공정한 경고: 이것은 보기만큼 간단하지 않습니다. 모델을 ONNX 형식으로 내보내고 애플리케이션에 로드하는 프로세스는 매우 복잡할 수 있으며 항상 작동하지 않을 수 있습니다. 그러나 슬픈 사실은 이것이 오늘날 온디바이스 기계 학습의 상태라는 것입니다. ONNX는 딥 러닝 프레임워크의 광범위한 지원을 받는 주요 도구인 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core ML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core ML은 Swift 프로그래밍 언어를 사용하는 대부분의 Apple 장치에서 작동하도록 Apple이 설계한 프레임워크입니다. 최신 iPhone에 있는 CPU, GPU 및 \"신경 컴퓨팅 엔진\"을 활용합니다. Core ML은 Apple 장치에만 해당되지만 상당한 지원을 제공하는 것 같습니다. 오늘날 최고의 NLP 소프트웨어 개발 회사 중 하나인 Hugging Face는 iPhone에서 Core ML 및 Swift와 함께 GPT-2 및 BERT와 같은 최신 모델을 실행하기 위한 몇 가지 데모도 발표했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Accelerators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난 몇 년 동안 몇몇 회사에서 에지 장치에 대한 추론을 위한 맞춤형 하드웨어를 만들기 시작했습니다. 그 중에는 Intel의 Movidius 컴퓨팅 스틱, Google의 Edge TPU 및 Nvidia Jetson 개발자 보드 제품군이 있습니다.\n",
    "\n",
    "이러한 장치는 모바일 사용을 위한 웹용으로 설계되지 않았습니다. 오히려 맞춤형 IoT 장치, 스마트 응용 프로그램 및 로봇 응용 프로그램과 함께 사용하기 위한 것입니다. 이와 같은 제품을 만들고 있다면 무엇을 사용해야 하는지 이미 알고 있을 것입니다. 또한 이들은 일반적으로 NLP보다 컴퓨터 비전과 더 관련이 있으므로 자세히 논의하지 않습니다.\n",
    "\n",
    "이러한 도구가 얼마나 새로운지 감안할 때 아직 선호하는 도구가 없습니다.\n",
    "\n",
    "다음으로, 오늘날 시장에 나와 있는 주요 클라우드 공급자를 다루겠습니다. 이것은 소프트웨어 스택에 대해 내려야 할 가장 중요한 결정 중 하나가 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Inference & Machine Learning as a Service (MLaaS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오늘날 가장 지배적인 세 가지 클라우드 인스턴스 제공업체는 AWS, GCP 및 Microsoft Azure입니다. 올바른 클라우드 공급자를 선택하려면 전체 IT 조직과 상의해야 하므로 여기에서 권장 사항을 제공하기 어렵습니다. 즉, 기계 학습과 관련하여 클라우드 공급자의 장단점을 검토해 보겠습니다.\n",
    "\n",
    "3대 서비스 모두 데이터 전처리, 모델 교육, 모델 평가, 모델 배포와 같은 작업을 처리하는 MLaaS(Machine Learning as a Service)를 제공하므로 이 부분도 고려할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS는 지금까지 클라우드 제공업체 중 가장 크고 지배적이었습니다. 전체 시장 점유율의 3분의 1을 차지하고 있는 반면, 2위인 마이크로소프트는 18%의 시장 점유율을 가지고 있습니다. 그러나 Google은 특히 AI에 강하고 AI 애플리케이션이 계속해서 번창함에 따라 빠르게 성장하고 있습니다.\n",
    "\n",
    "AWS는 사용 가능한 가장 큰 서비스 세트와 전 세계 데이터 센터의 가장 포괄적인 네트워크를 보유하고 있습니다. 클라우드 제공업체 중 가장 성숙하고 엔터프라이즈급으로 제공됩니다. 즉, AWS는 비용 구조에 대한 투명성이 낮고 초보자가 이해하기 가장 쉽지 않습니다. 또한 전적으로 퍼블릭 클라우드 게임에 속하며 Microsoft와 같은 하이브리드 클라우드 배포를 지원하지 않습니다.\n",
    "\n",
    "Amazon의 MLaaS 제품을 Amazon SageMaker라고 합니다. 완전 관리형 서비스이며 종단 간 기계 학습 작업을 처리하여 모델을 교육, 미세 조정, 배포 및 관리할 수 있습니다. 또한 SageMaker는 이전에 논의한 실험 추적 소프트웨어와 동일한 많은 기능을 제공합니다.\n",
    "\n",
    "Amazon에는 즉시 사용 가능한 NLP를 위한 여러 음성 및 텍스트 처리 API도 있습니다. 여기에는 Amazon Lex(챗봇), Amazon Transcribe(음성 텍스트 변환), Amazon Polly(텍스트 음성 변환), Amazon Comprehend(텍스트 분석, 예: 명명된 엔터티 인식, 언어 인식, 감정 분석 및 주제 모델링) 및 Amazon Translate(기계 번역)가 포함됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft Azure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft는 엔터프라이즈 클라이언트와 관련하여 큰 이점이 있습니다. 많은 엔터프라이즈 고객이 Windows 및 Office 365와 같은 Microsoft 제품을 사용하는 데 익숙합니다. Azure는 이러한 다른 Microsoft 제품과 긴밀하게 통합되어 엔터프라이즈 클라이언트가 Azure를 더 쉽게 채택할 수 있습니다. 긴밀한 제품 결합을 통해 Microsoft는 엔터프라이즈 고객에게 할인을 제공할 수도 있습니다.\n",
    "\n",
    "Microsoft의 MLaaS 오퍼링을 Azure Machine Learning이라고 합니다. SageMaker와 비교할 때 Microsoft는 그래픽 끌어서 놓기 인터페이스를 제공하는 초보자에게 더 친숙한 옵션을 제공합니다.\n",
    "\n",
    "Microsoft는 또한 음성 및 텍스트 분석을 위한 높은 수준의 NLP API를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Cloud Platform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google은 블록의 신인이지만 데이터 및 기계 학습 작업을 위한 최고의 제품 중 하나입니다. 그러나 Amazon 또는 Microsoft와 동일한 규모 및 다양한 제품을 제공하지는 않으므로 나머지 IT 조직에서는 GCP보다 AWS 또는 Azure를 선호할 수 있습니다.\n",
    "\n",
    "Google에는 Cloud AutoML과 Google Cloud Machine Learning Engine의 두 가지 MLaaS 옵션이 있습니다. Google Cloud AutoML은 초보자를 위한 것으로 사용자가 데이터 세트를 업로드하고 모델을 교육하고 API로 매우 빠르게 배포할 수 있습니다. Google Cloud ML Engine은 숙련된 사용자를 위한 것으로, 사용 편의성을 제공하는 대신 더 많은 유연성을 제공합니다. Amazon SageMaker와 매우 유사합니다.\n",
    "\n",
    "Amazon 및 Microsoft와 마찬가지로 Google은 높은 수준의 NLP API를 제공하지만 경쟁업체에 비해 주요 이점은 사용자가 Google의 AutoML 플랫폼을 사용하여 사용자 지정 모델을 교육할 수 있다는 것입니다.\n",
    "\n",
    "우리의 선택은 다음과 같습니다.\n",
    "\n",
    "안쿠르의 선택  \n",
    "제 선택은 AWS입니다. 기업에서 가장 널리 채택된 클라우드 제공업체로서 가장 크고 강력한 제품 세트를 제공합니다. 즉, 선택하는 클라우드 공급자는 나머지 조직에서 사용하는 것을 기반으로 해야 합니다.\n",
    "\n",
    "아제이의 선택  \n",
    "제 경험상 서버에서 추론을 실행하는 것이 모델을 배포하는 가장 간단한 방법입니다. 이렇게 하면 모델을 특별한 형식으로 내보내는 것에 대해 걱정할 필요 없이 PyTorch 코드를 실행할 수 있기 때문입니다. 이를 염두에 두고 애플리케이션에서 이미 사용하고 있는 모든 클라우드 공급자를 사용하는 것이 좋습니다. 아마도 가격을 제외하면 AWS, Azure 및 GCP의 딥 러닝 오퍼링 간에는 큰 차이가 없습니다. 여기에서 결정적인 요소는 애플리케이션의 다른 구성 요소에 가장 좋은 이점이 무엇인지입니다.\n",
    "\n",
    "다음으로 프로덕션에서 모델에 대한 변경 사항을 배포하기 전에 테스트 프로세스를 자동화하는 데 도움이 되는 도구에 대해 논의하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CI/CD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 장에서는 마지막 항목인 CI/CD(지속적인 통합 및 제공)를 제외하고 프로덕션에서 기계 학습 모델을 교육, 배포 및 관리하는 데 필요한 모든 ML 인프라 및 소프트웨어에 대해 논의했습니다. CI/CD는 우리와 같은 개발자가 프로덕션에서 코드 변경 사항을 자주 안정적으로 제공하는 데 도움이 되는 일련의 사례입니다. CI/CD는 모델이 제공하는 서비스를 장기간 중단하지 않고 프로덕션에서 ML 모델을 유지 관리할 수 있는 프로세스로 생각할 수 있습니다(예: 현재 모델을 새로 훈련된 모델로 교체).\n",
    "\n",
    "CI/CD를 풀어봅시다. CI는 개발자가 코드베이스에 대한 작은 변경 사항을 자주(한 번에 큰 변경 사항이 아닌) 구현하고 버전 코드 리포지토리에 자주 푸시하여 코드 버전을 지정하도록 권장하는 일련의 관행입니다. 그러나 개발자가 코드 베이스에 추진하는 모든 작은 변경 사항을 지원하려면 수행 중인 모든 변경 사항을 통합하고 유효성을 검사하고 개발자가 설정한 특정 표준을 준수하는 변경 사항을 수락하고 실패한 변경 사항을 거부하는 자동화된 프로세스가 필요합니다. 이러한 테스트를 통과하면 이것이 CI가 관리하는 것입니다.\n",
    "\n",
    "커밋이 작고 빈번한 경우(이상적으로는 매일)와 매우 크고 드문 경우에 코드 변경 문제를 식별하는 것이 더 쉽습니다.\n",
    "\n",
    "CD는 다운스트림 인프라 환경에 대한 애플리케이션 제공을 자동화하는 일련의 관행입니다. 예를 들어 CD는 최신 버전의 응용 프로그램을 배포하기 위해 다양한 환경에서 서비스를 다시 시작할 수 있습니다.\n",
    "\n",
    "우리의 선택은 다음과 같습니다.\n",
    "안쿠르의 선택  \n",
    "내 선택은 GitHub Acitons입니다. GitHub는 코드 리포지토리 및 코드 버전 관리 중에서 지배적인 플레이어입니다. GitHub Actions는 GitHub가 제공하는 기존 기능과 잘 통합됩니다. 즉, GitLab을 주시하십시오. GitHub에서 일부 시장 점유율을 빼앗고 있습니다.\n",
    "\n",
    "아제이의 선택  \n",
    "깃허브 액션! Actions는 이미 GitHub에 내장되어 있으므로 리포지토리와 통합하기가 매우 쉽습니다. GitHub 마켓플레이스는 pip에 게시, 테스트, 스타일 검사 등에 즉시 사용할 수 있는 작업을 제공합니다. GitHub는 Actions에도 새로운 특징과 기능을 추가하는 데 큰 역할을 하고 있는 것 같습니다. 따라서 이 제품에서 더 많은 발전이 있을 것으로 기대합니다. 재미있는 사실: wandb용 GitHub Action도 있습니다(https://oreil.ly/aDeeO).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 장에서는 딥 러닝 프레임워크, 시각화 및 실험 추적, AutoML, ML 인프라 및 컴퓨팅, 에지/온디바이스 추론, 클라우드 추론 및 기계를 포함하여 NLP에서 작업하는 동안 만나게 될 많은 주요 기계 학습 도구를 살펴보았습니다. 서비스로서의 학습 및 CI/CD. 우리는 또한 귀하의 선택에 도움이 될 개인적인 선택을 제공했습니다. 즉, 조직의 다른 사람들도 채택하고 있거나 채택한 것을 염두에 두십시오.\n",
    "\n",
    "11장에서 Databricks를 사용하여 대규모로 모델 배포를 시작하기 전에 Streamlit을 사용하여 기계 학습을 위한 간단한 웹 앱 배포를 살펴보겠습니다. 웹 앱은 기술 ​​지식이 없는 사용자가 구축한 기계 학습 애플리케이션에 액세스하고 반복할 수 있는 한 가지 방법입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
