{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ch03]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Tasks and Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2장에서는 언어 모델과 미세 조정에 대해 정성스럽게 소개했습니다. 이제 미세 조정을 실제로 *사용*할 수 있는 대상에 대해 자세히 살펴보겠습니다. 미세 조정은 이전 장에서 언급한 것처럼 더 나은 도메인별 언어 모델을 생성하는 것 이상의 의미가 있습니다. 미세 조정은 복잡한 실제 NLP 응용 프로그램의 빌딩 블록 역할을 하는 의미 있는 실제 작업을 해결하는 데 사용할 수 있습니다.\n",
    "\n",
    "이 장에서는 이러한 \"보다 의미 있는\" 실제 작업 중 몇 가지를 공식적으로 소개하고 이러한 작업의 성능을 측정하기 위한 몇 가지 인기 있는 벤치마크를 제시합니다. (예: [GLUE](https://gluebenchmark.com/) 및 [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) 또한 이러한 작업을 직접 해결할 때 사용할 수 있는 몇 가지 공개적으로 사용 가능한 표준 데이터 세트를 강조 표시합니다. 그리고 가장 중요한 것은 이 두 가지 작업(명명된 엔터티 인식 및 텍스트 분류)을 함께 해결하여 이 모든 것이 어떻게 작동하는지 보여줄 것입니다.\n",
    "\n",
    "이 장이 NLP 수행에 대한 더 깊고 더 많은 적용 및 실습을 제공하고 실제 NLP 응용 프로그램을 구축할 수 있는 발판 역할을 할 수 있기를 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Language Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1장에서 언급했듯이 NLP는 지난 몇 년 동안 짧은 시간에 많은 발전을 이루었습니다. NLP 모델을 처음부터 훈련하는 대신 이제 사전 훈련된 언어 모델을 활용하여 명명된 엔터티 인식과 같은 일반적인 NLP 작업을 수행하는 것이 가능하고 권장됩니다. 고도의 맞춤형 NLP 요구 사항이 있는 경우에만 NLP 모델을 처음부터 훈련하는 것이 좋습니다. 그러나 계속 진행하기 전에 이 장에서 사용할 용어를 정의해 보겠습니다. 이러한 용어 중 일부는 이전 두 장에서 이미 다루었습니다. 그러나 이것은 그럼에도 불구하고 모든 것을 하나로 묶는 좋은 재충전이 될 것입니다.\n",
    "\n",
    "> 참고: NLP 작업을 수행하기 위해 자연어 데이터로 훈련된 모델은 컴퓨터 비전 작업을 수행하기 위해 이미지 또는 비디오와 같은 시각적 데이터로 훈련된 컴퓨터 비전 모델과 같은 다른 유형의 모델과 달리 일반적으로 NLP 모델로 알려져 있습니다. 언어 모델은 2장에서 소개한 언어 모델링을 수행하도록 훈련된 특정 유형의 NLP 모델입니다.\n",
    "\n",
    "기계 학습은 기계가 더 많은 데이터에서 학습함에 따라 작업 성능이 향상되도록 데이터로부터 학습하여 정의된 작업에 대한 성능을 향상할 수 있는 능력을 기계에 제공하는 인공 지능의 응용 프로그램입니다.\n",
    "\n",
    "자연어 처리는 텍스트 및 음성과 같은 자연어(\"인간\"이라고도 함)를 포함하는 기계 학습의 한 분야입니다. 이 책에서 다루지 않을 컴퓨터 비전은 이미지, 비디오와 같은 시각적 데이터를 포함하는 기계 학습의 한 분야입니다.\n",
    "\n",
    "기계는 레이블이 지정된 데이터 또는 레이블이 지정되지 않은 데이터에서 학습할 수 있습니다. 레이블이 지정된 데이터(예: \"고양이\" 또는 \"개\"의 이미지)를 포함하는 기계 학습 영역을 지도 학습이라고 합니다. 레이블이 지정되지 않은 데이터(예: 고양이와 개 이미지가 있음)를 포함하는 영역을 비지도 학습이라고 합니다. 각주:[궁금하시면 Ankur에 [실습 비지도 학습에 관한 전체 책](www.unsupervisedlearningbook.com)이 있습니다.]. 강화 학습으로 알려진 기계 학습의 세 번째 주요 영역은 받는 보상을 최대화하기 위해 환경(물리적 또는 디지털)에서 조치를 취하는 방법을 배우는 소프트웨어 에이전트와 관련됩니다.\n",
    "\n",
    "기계 학습에서 특정 작업에 대한 성능을 향상시키기 위해 데이터에서 기계를 학습하는 프로세스(\"데이터 교육\"이라고도 함)는 모델을 생성합니다. 기계가 작업에 대해 만족스러운 수준의 성능을 학습/훈련하면 모델은 훈련 과정에서 얻은 지식을 모델 매개변수(예: 가중치)의 형태로 저장합니다. 기계 학습에서 수행되는 미적분 및 선형 대수에 사용됩니다.\n",
    "\n",
    "모델은 이 저장된 지식(예: 모델 매개변수)을 사용하여 새로운/한 번도 본 적이 없는 데이터에 대한 추론(예: 예측 생성)을 수행합니다. 새 데이터가 기계가 훈련한 데이터와 유사하다면 새 데이터의 성능은 기계가 원래 훈련 데이터 세트에서 달성한 성능과 유사해야 합니다.\n",
    "\n",
    "원래 주제로 돌아가서 사전 훈련된 언어 모델을 사용하여 일반적인 NLP 작업을 수행할 수 있습니다. 사전 훈련된 모델을 참조할 때 이전에 데이터에 대해 훈련된 모델을 참조합니다. 기계가 NLP 작업을 수행하기 위해 처음부터 데이터를 훈련시키는 대신, 좋은 수준의 성능을 위해 *언어 모델링*을 수행하기 위해 수많은 데이터에 대해 이미 훈련된 사전 훈련된 *언어* 모델로 시작합니다. 그런 다음 사전 훈련된 언어 모델을 *미세 조정*하여 언어 모델링을 넘어 특정 NLP 작업을 수행합니다. 다른 NLP 작업을 수행하기 위해 언어 모델을 미세 조정하는 이 프로세스를 전이 학습이라고 하며 다음에 살펴볼 것입니다. (걱정하지 마세요: 이러한 *일반적인* NLP 작업이 무엇인지 곧 논의할 것입니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning and Fine-tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 학습된 언어 모델을 사용하는 것이 일반적인 NLP 작업을 수행하는 가장 빠른 방법입니다. 반대로 일반적이지 않은 NLP 작업을 수행해야 하는 경우 작업과 관련된 데이터 소싱 및 주석 달기/레이블 지정을 포함하여 처음부터 모델을 훈련해야 할 수 있습니다.\n",
    "\n",
    "작업이 사전 학습된 모델이 수행하도록 훈련된 작업과 유사하지만 정확히 동일하지는 않은 경우가 있습니다. 이러한 경우 모델을 완전히 처음부터 훈련하는 대신 사전 훈련된 모델의 \"사전 학습\" 중 일부를 활용할 수 있습니다. 이 \"사전 학습\" 중 일부를 활용하여 자신의 모델을 훈련하는 것을 전이 학습이라고 합니다. 한 모델에서 다른 모델로 학습을 효과적으로 \"전송\"하고 있습니다.\n",
    "\n",
    "Transfer learning is possible because pretrained language models are neural networks. Neural networks are a class of models in machine learning in which machines learn to represent data in a manner which enables the machines to perform complex tasks such as classifying the data.\n",
    "\n",
    "사전 훈련된 언어 모델이 신경망이기 때문에 전이 학습이 가능합니다. 신경망은 기계가 특정 방식으로 데이터를 표현하는 방법을 학습하는 기계 학습의 모델 클래스입니다. 기계가 데이터 분류와 같은 복잡한 작업을 수행할 수 있도록 합니다.\n",
    "\n",
    "신경망은 일반적으로 일련의 표현 학습을 포함합니다. 각각의 후속 표현은 기계가 이전 표현의 데이터를 더 쉽게 해석할 수 있도록 합니다. 각 표현은 신경망의 계층에서 학습됩니다. 신경망에 레이어가 많을수록 더 많은 표현이 학습됩니다. 현대 신경망에는 일반적으로 많은 계층이 있습니다. 즉, 신경망은 매우 깊습니다. 여기에서 \"딥 러닝\"과 \"딥 뉴럴 네트워크\"라는 용어가 나옵니다(그림 3-0 참조).\n",
    "![Neural Network](images/hulp_0300.png)\n",
    "\n",
    "전이 학습에서는 사전 훈련된 *언어 모델*의 처음 여러 계층을 차용합니다. 이러한 처음 몇 개의 계층은 이미 데이터의 유용한 표현을 학습했기 때문에 특정 작업을 위해 신경망의 후속 계층을 더 쉽게 훈련할 수 있습니다.\n",
    "\n",
    "예를 들어 사전 학습된 언어 모델의 처음 여러 계층은 텍스트의 다양한 토큰을 나타내는 좋은 방법을 이미 발견했을 수 있습니다. 이러한 표현을 처음부터 배우는 대신 사전 훈련된 모델이 학습한 지식을 빌린 다음 특정 작업에 대해 모델을 좀 더 훈련할 수 있습니다.\n",
    "\n",
    "사전 훈련된 모델의 처음 여러 계층을 빌린 후 수행하는 모델의 추가 훈련을 미세 조정이라고 합니다. 즉, 사전 훈련된 모델 중 일부를 가져와 획득한 지식 중 일부를 전송한 다음 특정 작업을 위해 신경망의 나머지 계층을 미세 조정합니다.\n",
    "\n",
    "전이 학습 및 미세 조정은 오늘날 NLP에서 매우 일반적인 관행이며 특정 도메인(예: 금융, 법률 등)에서 NLP 애플리케이션 구축을 가속화하는 데 도움이 되었습니다. 한 도메인에서 다른 도메인으로 전환할 때마다(예: 재무 문서 분석에서 법률 문서로) NLP 모델을 처음부터 훈련해야 한다면 NLP 애플리케이션 구축은 매우 느리고 힘든 과정이 될 것입니다.\n",
    "\n",
    "대신, 우리는 웹에서 크롤링된 많은 텍스트 데이터에 대해 훈련된 일반적인 사전 훈련된 언어 모델을 활용하고 재무 또는 법률을 위해 미세 조정하고 도메인별 언어 모델을 신속하게 구축할 수 있습니다. 2. 전이 학습은 최근 몇 년 동안 업계에서 NLP가 꽃을 피운 이유입니다.\n",
    "\n",
    "이러한 맥락을 염두에 두고 일반적인 NLP 작업을 소개하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face에는 훌륭한 [일반적인 NLP 작업 개요](https://huggingface.co/transformers/task_summary.html)가 있으며, 지금 여기서 소개할 것입니다. 이러한 작업에는 시퀀스 분류, 질문 응답, 언어 모델링, 명명된 엔터티 인식(named entity recognition), 요약 및 번역이 포함됩니다. 이 목록이 완전한 것은 아니지만 이 목록은 오늘날 응용 프로그램 구축에서 NLP의 가장 빈번한 사용 사례를 강조하고 시작하기에 좋은 곳입니다.\n",
    "\n",
    "- **서열 분류:** 서열 분류는 말처럼 간단합니다. 시퀀스를 주어진 수의 클래스로 분류하는 작업이 포함됩니다. 텍스트에 대해 수행할 때 시퀀스 분류는 텍스트 분류라고도 하며 이 장의 뒷부분에서 함께 수행할 것입니다. 시퀀스 분류의 예는 2장에서 IMBD 영화 리뷰를 긍정적, 부정적 또는 중립으로 분류할 때 수행한 감정 분석입니다. 각각) 세 부류 중 하나로 분류: 긍정적 함의(가설은 텍스트의 상황이나 사건에 대해 확실히 옳은 것을 진술함), 중립적 함의(가설은 텍스트의 상황이나 사건에 대해 정확할 수 있는 것을 진술함) 또는 부정적 함의(가설은 전제의 상황이나 사건에 대해 확실히 잘못된 것이 있음을 나타냅니다). NLP 분야에서는 기계가 이 작업을 잘 수행하기 위해 데이터에서 추론할 수 있어야 하는 것을 고려할 때 보다 구체적으로 NLU(자연어 이해) 작업이라고 합니다. [GLUE(General Language Understanding Evaluation) 벤치마크](https://gluebenchmark.com/)는 보다 일반적으로 시퀀스 분류 작업 및 자연어 이해의 진행 상황을 측정하는 가장 인기 있는 벤치마크입니다. 원본 GLUE 논문의 저자는 [SuperGLUE](https://super.gluebenchmark.com/)로 알려진 NLU의 진행 상황을 측정하기 위해 훨씬 더 어려운 벤치마크를 발표했습니다. Papers with Code에서 더 많은 [텍스트 분류 데이터 세트](https://paperswithcode.com/task/text-classification)를 찾을 수 있습니다.\n",
    "\n",
    "- **질문 응답:** 질문 응답은 질문에 주어진 일련의 텍스트 또는 오디오에서 정답을 제공하는 작업입니다. 이것을 독해력이라고 생각하십시오. 기계는 읽기 구절에서 올바른 텍스트 부분을 찾아 질문에 대한 답변으로 제시해야 합니다. 질문 답변 진행 상황을 측정하는 가장 인기 있는 벤치마크는 [SQuAD 2.0](https://rajpurkar.github.io/SQuAD-explorer/)입니다. 원래 SQuAD 데이터 세트(SQuAD 1.1로 알려짐)의 답변 가능한 질문 100,000개와 답변 가능한 질문과 유사해 보이는 답변 불가능한 질문 50,000개의 모음입니다. 기계를 속이기 위해 대답할 수 없는 질문이 도입되어 작업이 더 어려워졌습니다. 기계는 질문에 답할 수 있는지 여부를 결정해야 하며, 질문에 대답할 수 있으면 기계가 정답을 제공해야 합니다.\n",
    "\n",
    "- **Language Modeling:** 우리는 이미 언어 모델링을 다루었지만, 언어 모델링은 단어 시퀀스가 ​​주어지면 다음 단어 시퀀스를 예측하는 작업입니다. 이 특정 유형의 언어 모델링은 *인과적 언어 모델링*으로 알려져 있으며 NLP 분야의 *자연어 생성*(NLG)에 일반적으로 사용됩니다. 또 다른 유형의 언어 모델링은 *마스크된 언어 모델링*으로, 기계는 마스킹된 단어 또는 단어 주변의 컨텍스트가 주어진 시퀀스에서 마스킹된 단어를 예측해야 합니다. 이 작업의 특성상 업계 설정 성능 벤치마크는 없지만 사용할 수 있는 [데이터 세트](https://paperswithcode.com/task/language-modelling)가 많이 있습니다.\n",
    "\n",
    "- **텍스트 생성:** 텍스트 생성은 작업이 주어진 텍스트의 연속인 일관된 텍스트 시퀀스를 생성하는 작업을 포함한다는 점에서 언어 모델링과 유사하지만 텍스트 생성은 언어 모델링에 비해 더 개방적입니다. 텍스트 생성을 언어 모델링과 관련된 더 짧은 시퀀스 텍스트 예측과 더 긴 시퀀스 텍스트 예측으로 생각하십시오. 텍스트 생성은 2019년 [OpenAI's GPT-2](https://openai.com/blog/better-language-models/)의 출시와 함께 주류 인기를 얻었습니다. 이 작업에 대한 업계 성능 벤치마크는 없지만 다음은 일부입니다. [데이터 세트](https://paperswithcode.com/task/text-generation).\n",
    "\n",
    "- **개체명 인식(named entity recognition):** 1장에서 개체명 인식(NER)을 소개했습니다. 일련의 토큰(생각하는 문장)에서 관심 있는 토큰(단어를 생각하는 것)을 사람, 조직 또는 위치와 같은 특정 엔터티 유형으로 분류하는 작업입니다. 이 작업에 대한 가장 인기 있는 데이터 세트 및 벤치마크는 [CoNLL-2003](https://www.clips.uantwerpen.be/conll2003/ner/)이며, 이는 2003년으로 거슬러 올라가는 NER 도전 과제입니다. 당시 통계적 NLP 모델은 NER를 수행하는 데 사용되었지만 오늘날 가장 성능이 좋은 NER 모델은 변압기 기반입니다. 데이터 세트를 포함한 NER에 대한 자세한 내용은 [Papers with Code](https://paperswithcode.com/task/named-entity-recognition-ner) 웹사이트를 방문하세요. 이 장의 뒷부분에서 함께 NER을 수행할 것입니다.\n",
    "\n",
    "- **요약:** 요약은 문서를 더 짧은 텍스트로 요약하는 작업입니다. 이 작업의 유용성은 완전히 명백해야 합니다. 이것은 우리 모두가 매일 수행하는 작업으로, 긴 기사의 정보를 짧은 블록/요약으로 합성하여 메모리로 유지합니다. 이 작업에 대한 업계 성능 벤치마크 및 데이터 세트는 [CNN / Daily Mail](https://paperswithcode.com/sota/document-summarization-on-cnn-daily-mail)이며, 다음은 일부 [공개 데이터 세트](https ://paperswithcode.com/task/text-summarization)에서 사용할 수 있습니다.\n",
    "\n",
    "- **번역:** 번역(또는 흔히 말하는 기계 번역)은 텍스트를 언어에서 다른 언어로 번역하는 작업입니다. Google 번역 또는 Apple의 번역 앱을 생각해 보십시오. 기계 번역의 품질을 평가하는 가장 인기 있는 지표는 [BLEU](https://en.wikipedia.org/wiki/BLEU)입니다. 또한 Papers with Code에서 이 작업에 대한 [많은 데이터 세트](https://paperswithcode.com/task/machine-translation)를 찾을 수 있습니다.\n",
    "\n",
    "다시 말하지만, 이 목록은 결코 완전하지 않습니다. 이들은 오늘날 NLP의 빈번한 사용 사례 중 일부에 불과합니다. 다른 사용 사례로는 보이스봇, 챗봇, 음성 인식, 엔터티 연결(1장에서 살펴봄) 등이 있습니다. 그럼에도 불구하고 이것은 NLP가 오늘날 응용 프로그램에서 어떻게 사용되고 있는지에 대한 정보를 제공해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 NLP 작업을 다루었으므로 미리 훈련된 언어 모델을 사용하여 이러한 NLP 작업 중 두 가지(명명된 엔터티 인식 및 텍스트 분류)를 수행해 보겠습니다. 그 전에 작업할 자연어 데이터 세트가 필요합니다.\n",
    "\n",
    "이 장에서는 AG News Classification Dataset을 사용합니다. AG는 2,000개 이상의 뉴스 소스에서 수집한 100만 개 이상의 뉴스 기사 모음입니다. 이 데이터 세트는 학계에서 제공되며 일반적으로 연구 목적으로 사용됩니다(예: 수년 동안 다양한 NLP 모델의 성능을 벤치마킹하기 위해).각주:[데이터 세트에 대한 자세한 내용은 [원본 소스](http:/ /groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html).]\n",
    "\n",
    "Xiang Zhang이 구성하고 Kaggle.footnote에서 사용할 수 있는 이 AG 뉴스 분류 데이터 세트의 특정 버전을 사용합니다.[데이터 세트에 대한 자세한 내용은 [Kaggle](https://www.kaggle의 데이터 세트 페이지를 참조하십시오. .com/amananandrai/ag-news-classification-dataset).] 이 버전의 데이터 세트는 문서가 더 좋고 CSV(쉼표로 구분된 값) 파일로 쉽게 사용할 수 있지만 원본은 그렇지 않습니다.\n",
    "\n",
    "지금부터 AG News Topic Classification Dataset(\"AG Dataset\")이라고 부르는 이 Kaggle 버전의 데이터 세트는 레이블이 지정된 데이터 세트입니다. 각 뉴스 기사에는 제목과 설명이 있으며 4가지 클래스(1-World, 2-Sport, 3-Business 및 4-Sci/Tech) 중 하나로 분류됩니다. 각 클래스에는 30,000개의 교육 샘플과 1,900개의 테스트 샘플이 포함되어 있으며 전체 데이터 세트에는 120,000개의 교육 샘플과 7,600개의 테스트 샘플이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore AG Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google에서 학습 데이터 세트를 살펴보겠습니다. Colab.각주:[따라가려면 [Github 저장소](https://github.com/nlpbook/nlpbook/)의 Chapter 3 노트북을 방문하세요.] GPU를 사용하여 모델을 훈련시키려고 하므로 Google Colab(또는 GPU를 사용할 수 있는 경우 로컬)에서 GPU를 활성화하겠습니다. Google Colab 세션에서 편집 → 노트북 설정으로 이동하고 하드웨어 가속기에서 GPU를 선택한 다음 저장을 누릅니다. 이렇게 하면 런타임이 다시 시작됩니다. 모든 셀 상태가 손실됩니다.\n",
    "\n",
    "다음으로 데이터를 로드하고 모든 열 이름을 소문자로 변환하고 공백을 밑줄로 바꾸고 숫자 레이블을 클래스 이름에 매핑하는 \"class_name\"이라는 새 기능을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Import AG Dataset\n",
    "data = pd.read_csv(cwd+'/data/ag_dataset/train.csv')\n",
    "data = pd.DataFrame(data=data)\n",
    "data.columns = data.columns.str.replace(\" \",\"_\")\n",
    "data.columns = data.columns.str.lower()\n",
    "data[\"class_name\"] = data[\"class_index\"].map({1:\"World\", 2:\"Sports\", \n",
    "                                              3:\"Business\", 4:\"Sci_Tech\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터를 미리 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# View data\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셀 출력에서 ​​볼 수 있듯이 학습 데이터 세트에는 예상대로 120,000개의 관찰과 4개의 기능이 있습니다. 4가지 기능은 class_index, 제목, 설명 및 class_name입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 클래스당 관측치 수입니다(각각 예상대로 30,000개)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Count observations by class\n",
    "data.class_name.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로, 데이터를 더 잘 이해하기 위해 처음 10개의 뉴스 기사의 제목과 설명을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# View titles\n",
    "for i in range(10):\n",
    "    print(\"Title of Article\",i)\n",
    "    print(data.loc[i,\"title\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# View descriptions\n",
    "for i in range(10):\n",
    "    print(\"Description of Article\",i)\n",
    "    print(data.loc[i,\"description\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 제목과 설명을 기반으로 이제 설명에 다소 시끄러운 텍스트(예: 기사 8의 설명)를 포함하여 데이터에 대한 느낌이 더 좋아졌을 것입니다.\n",
    "\n",
    "데이터의 노이즈를 제거하기 위해 텍스트를 좀 더 사전 처리해 보겠습니다. 이렇게 하면 불필요한 토큰(예: 이중 공백)을 제거 및 교체하고 텍스트 읽기(인간의 경우)를 더 어렵게 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Clean up text\n",
    "cols = [\"title\",\"description\"]\n",
    "data[cols] = data[cols].applymap(lambda x: x.replace(\"\\\\\",\" \"))\n",
    "data[cols] = data[cols].applymap(lambda x: x.replace(\"#36;\",\"$\"))\n",
    "data[cols] = data[cols].applymap(lambda x: x.replace(\"  \",\" \"))\n",
    "data[cols] = data[cols].applymap(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Write data to CSV\n",
    "data.to_csv(cwd+'/data/ag_dataset/prepared/train_prepared.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "굉장히 좋습니다! 이것은 우리가 작업할 데이터 세트입니다. 이제 엔터티 인식이라는 첫 번째 NLP 애플리케이션을 진행해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Task #1 - Named Entity Recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1장에서는 주목할만한 엔터티를 자연어로 구문 분석하고 \"사람\" 또는 \"위치\"와 같은 적절한 클래스 레이블로 레이블을 지정하는 명명된 엔터티 인식(NER)에 대해 간략하게 살펴보았습니다. 명명된 엔터티 인식은 텍스트 분류의 한 형태입니다. NER 모델은 관심 토큰 주변의 토큰 컨텍스트를 사용하여 관심 토큰의 엔터티 레이블을 예측합니다. 엔터티에 올바르게 레이블이 지정되면 추출된 정보를 사용하여 정보 검색(관심 있는 사람이나 장소를 기반으로 문서 검색)을 수행하고, 비정형 문서에서 구조화된 데이터를 생성할 수 있습니다(예: 대규모 법률 문서에서 주요 구속력 있는 법률 용어 구문 분석). , 그리고 더. NER을 모든 문서에 풍부한 메타데이터를 추가하는 것으로 생각하면 풍부한 분석 다운스트림을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Inference using Original SpaCy Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 SpaCy의 사전 학습된 언어 모델을 사용하여 명명된 엔터티 인식을 수행해 보겠습니다. SpaCy는 NER용으로 소형, 중형, 대형 및 변압기 기반의 네 가지 사전 훈련된 모델을 제공합니다. 네 가지 모두 블로그, 뉴스 및 댓글 형식의 서면 텍스트에 대해 교육을 받았지만 크기는 다릅니다. 모델이 클수록 훈련된 데이터가 많을수록 일반적으로 성능이 향상됩니다. 1장에서는 기본 NLP 작업을 수행하기 위해 작은 모델을 선택했습니다. 이제 spaCy의 베스트 모델인 트랜스포머 기반 모델을 선택하겠습니다.\n",
    "\n",
    "> 참고: spacy[cuda110]을 지정하여 GPU에 spaCy를 설치합니다. 다른 CUDA 버전도 지정할 수 있습니다. 자세한 내용은 [spaCy 설명서](https://spacy.io/usage)를 참조하세요. GPU를 사용하지 않으려면 pip install -U spacy(cuda 참조 없이)를 사용하여 spacy를 설치하십시오. 문제가 발생하면 authors@appliednlpbook.com으로 이메일을 보내주십시오."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직 spaCy를 설치하지 않으셨다면, 이 명령은 필요한 모든 것을 제공합니다. 노트북에서 실행하는 경우 우리가 전에 했던 것처럼 각 행에 `!` 문자를 붙입니다.\n",
    "\n",
    "```bash\n",
    "pip install -U spacy[cuda110,transformers,lookups]==3.0.3\n",
    "pip install -U spacy-lookups-data==1.0.0\n",
    "pip install cupy-cuda110==8.5.0\n",
    "python -m spacy download en_core_web_trf\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 경고: 다음 단계에서 모델을 성공적으로 가져오기 전에 spaCy를 설치하고 사전 학습된 언어 모델을 다운로드한 후 런타임을 다시 시작해야 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import spacy and load language model\n",
    "# To use GPU, uncomment the GPU-related code below\n",
    "\n",
    "import spacy\n",
    "# spacy.require_gpu()\n",
    "# print(spacy.require_gpu())\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 참고: GPU에 spaCy가 성공적으로 설치되고 활성화되면 \"GPU: True\"가 표시됩니다. 그렇지 않은 경우 GPU 설치 문제를 해결하거나 CPU로 되돌리십시오."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 spaCy를 설치하고 변환기(transformer) 기반 모델을 로드했으므로 모델의 기본 구성 요소와 관련 정확도 메트릭을 강조 표시하는 모델의 메타데이터를 인쇄해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# View metadata of the model\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(nlp.meta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메트릭(관련된 텍스트의 양을 고려할 때 여기에 인쇄하지 않음)을 기반으로 모델에 NER 구성 요소가 있음을 알 수 있습니다. 이 구성 요소는 추기경, 날짜, 이벤트, fac, gpe, 언어, 법률, 위치, 돈, 노르프, 서수, 조직, 퍼센트, 사람, 제품, 수량, 시간 및 예술 작품.\n",
    "\n",
    "ORG(조직의 줄임말), PERSON 및 GPE(즉, 국가, 도시 및 주와 같은 지정학적 엔터티)의 세 가지 보다 일반적인 엔터티 유형에 초점을 맞추겠습니다. 이 세 가지에 대한 정확도 메트릭을 검토해 보겠습니다. F는 F1 점수입니다. P는 Precision이고 R은 Recall입니다.\n",
    "\n",
    "다시 말해 정밀도는 참 긍정의 백분율/전체 긍정 예측의 수입니다. 재현율은 진양성의 백분율/총 진양성의 수입니다. F1은 혼합 메트릭이며 2 x (정밀도 x 재현율)/(정밀도 + 재현율)로 계산됩니다. F1, 정밀도 및 재현율이 높을수록 좋습니다.\n",
    "\n",
    "```\n",
    "'PERSON': {'f': 0.9546191248, 'p': 0.9481648422000001, 'r': 0.9611618799}\n",
    "\n",
    "'ORG': {'f': 0.9012772751, 'p': 0.9046474359000001, 'r': 0.8979321315000001}\n",
    "\n",
    "'GPE': {   'f': 0.9467271182, 'p': 0.9619925137, 'r': 0.9319386332}\n",
    "```\n",
    "\n",
    "이러한 지표에서 모델이 이러한 모든 엔터티에서 상당히 우수하지만 F1 점수가 90인 ORG에서는 최악임을 알 수 있습니다.\n",
    "\n",
    "이제 spaCy 모델을 로드하고 일부 메타데이터를 검토했으므로 spaCy 모델을 AG News 데이터에 적용하고 명명된 엔터티 인식 결과를 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Print NER results for Descriptions\n",
    "for i in range(9):\n",
    "    print(\"Article\",i)\n",
    "    print(data.loc[i,\"description\"])\n",
    "    print(\"Text Start End Label\")\n",
    "    doc = nlp(data.loc[i,\"description\"])\n",
    "    for token in doc.ents:\n",
    "        print(token.text, token.start_char,\n",
    "              token.end_char, token.label_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 태그가 지정된 모든 엔터티의 시작 및 끝 위치를 포함하여 처음 9개 기사의 설명에 대한 NER 레이블입니다. NER 모델의 성능을 검토해 봅시다.\n",
    "\n",
    "- Article 0: Reuters - Short-sellers, Wall Street's dwindling band of ultra-cynics, are seeing green again.\n",
    "- Text Start End Label\n",
    "- Reuters 0 7 ORG\n",
    "\n",
    "Great result.\n",
    "\n",
    "- Article 1: Reuters - Private investment firm Carlyle Group, which has a reputation for making well-timed and occasionally controversial plays in the defense industry, has quietly placed its bets on another part of the market.\n",
    "- Text Start End Label\n",
    "- Reuters 0 7 ORG\n",
    "- Carlyle Group 34 47 ORG\n",
    "\n",
    "Great result.\n",
    "\n",
    "- Article 2: Reuters - Soaring crude prices plus worries about the economy and the outlook for earnings are expected to hang over the stock market next week during the depth of the summer doldrums.\n",
    "- Text Start End Label\n",
    "- Reuters 0 7 ORG\n",
    "- next week 134 143 DATE\n",
    "- summer 168 174 DATE\n",
    "\n",
    "Great result. Even the date entities were captured correctly.\n",
    "\n",
    "- Article 3: Reuters - Authorities have halted oil export flows from the main pipeline in southern Iraq after intelligence showed a rebel militia could strike infrastructure, an oil official said on Saturday.\n",
    "- Text Start End Label\n",
    "- Reuters 0 7 ORG\n",
    "- Iraq 86 90 GPE\n",
    "- Saturday 186 194 DATE\n",
    "\n",
    "Great result.\n",
    "\n",
    "- Article 4: AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\n",
    "- Text Start End Label\n",
    "- AFP 0 3 ORG\n",
    "- barely three months 103 122 DATE\n",
    "- US 134 136 GPE\n",
    "\n",
    "Great result.\n",
    "\n",
    "- Article 5: Reuters - Stocks ended slightly higher on Friday but stayed near lows for the year as oil prices surged past $46 a barrel, offsetting a positive outlook from computer maker Dell Inc. (DELL.O)\n",
    "- Text Start End Label\n",
    "- Reuters 0 7 ORG\n",
    "- Friday 42 48 DATE\n",
    "- the year 74 82 DATE\n",
    "- 46 110 112 MONEY\n",
    "- Dell Inc. 173 182 ORG\n",
    "\n",
    "Great result.\n",
    "\n",
    "- Article 6: AP - Assets of the nation's retail money market mutual funds fell by $1.17 billion in the latest week to $849.98 trillion, the Investment Company Institute said Thursday.\n",
    "- Text Start End Label\n",
    "- 1.17 billion 69 82 MONEY\n",
    "- the latest week 86 101 DATE\n",
    "- 849.98 trillion 105 121 MONEY\n",
    "- the Investment Company Institute 123 155 ORG\n",
    "- Thursday 161 169 DATE\n",
    "\n",
    "AP should have been recognized as an organization, but otherwise great result.\n",
    "\n",
    "- Article 7: USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.\n",
    "- Text Start End Label\n",
    "- July 50 54 DATE\n",
    "- last week 97 106 DATE\n",
    "- Thursday 128 136 DATE\n",
    "- midsummer 181 190 DATE\n",
    "\n",
    "USATODAY.com should have been recognized as an organization, but otherwise great result.\n",
    "\n",
    "- Article 8: Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of $70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"buying insurance was the furthest thing from my mind,\" says Riley.\n",
    "- Text Start End Label\n",
    "- Danny Bazil Riley 49 66 PERSON\n",
    "- annual 145 151 DATE\n",
    "- 70,000 168 174 MONEY\n",
    "- 32 315 317 DATE\n",
    "- Riley 380 385 PERSON\n",
    "\n",
    "Forbes.com is an organization, and 32 is not a date.\n",
    "\n",
    "대체로 사전 훈련된 SpaCy 모델의 NER 결과는 훌륭합니다. 이것은 가능한 경우 작업에 사전 훈련된 모델을 활용해야 하는 이유를 강조합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom NER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 때때로 사전 학습된 모델이 당면한 작업에 충분하지 않습니다. 여기에는 여러 가지 이유가 있을 수 있습니다. 첫째, 사전 훈련된 모델을 적용하려는 말뭉치가 모델이 훈련된 말뭉치와 실질적으로 다를 수 있습니다. 예를 들어 방금 사용한 변환기 기반 spaCy 모델은 블로그, 뉴스 및 웹 댓글에 대해 학습되었습니다. 말뭉치가 실질적으로 다른 경우(예: 법률, 재무 또는 건강 데이터와 같은 매우 기술적인 말뭉치) 말뭉치의 일부에 주석을 달고 변환기 기반 spaCy 모델을 미세 조정해야 할 수 있습니다. 모델을 미세 조정하면 모델이 특정 말뭉치에서 더 잘 수행됩니다.\n",
    "\n",
    "둘째, 트랜스포머 기반 spaCy 모델이 수행하도록 훈련된 작업은 우리가 수행하려는 작업과 다를 수 있습니다. 예를 들어 spaCy 명명된 엔터티 인식은 엔터티 유형으로 주식 시세 표시기(TICKER)를 지원하지 않습니다. 이 TICKER 엔터티 유형을 추가하려면 데이터에 티커에 주석을 달고 변환기 기반 spaCy 모델을 미세 조정해야 합니다.\n",
    "\n",
    "전이 학습 및 모델 미세 조정이 어떻게 작동하는지 보여주기 위해 세 가지 핵심 엔터티 유형(ORG, PERSON 및 GPE)에 대한 데이터의 작은 부분에 주석을 달고 새 엔터티 유형(TICKER)을 추가해 보겠습니다.\n",
    "\n",
    "데이터에 주석을 달기 위해 Prodigy라는 주석 플랫폼을 사용할 것입니다. Prodigy는 spaCy와 마찬가지로 소프트웨어 회사 [Explosion](https://explosion.ai/)의 제품입니다. Prodigy를 사용하면 말뭉치를 아름다운 브라우저 기반 UI에 로드하여 원하는 대로 데이터에 레이블을 지정할 수 있습니다. 그런 다음 이러한 레이블을 사용하여 spaCy 모델을 미세 조정할 수 있습니다. 유감스럽게도 Prodigy는 무료로 사용할 수 없지만 구매할 것을 적극 권장합니다.\n",
    "\n",
    "다음 섹션에서는 Prodigy를 설치하고 사용하여 AG News 데이터 세트의 작은 부분에 주석을 추가합니다. 그런 다음 이러한 주석을 사용하여 이전의 spaCy 모델을 미세 조정합니다. Prodigy 라이선스 구매를 원하지 않는 분들은 다음 섹션을 건너뛰셔도 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate via Prodigy - NER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prodigy 라이선스를 구입하면 Python .whl 파일(휠이라고도 함)을 다운로드할 수 있습니다. 안타깝게도 이 휠은 Google Colab에 설치할 수 없으므로 자체 컴퓨터에 로컬로 설치해야 합니다.\n",
    "\n",
    "Prodigy를 설치하기 전에 로컬 컴퓨터에서 가상 환경을 만들고 활성화하는 것이 좋습니다. Python의 Anaconda 배포판이 설치되어 있는 경우 명령줄에서 다음 명령을 사용하여 새 가상 환경을 만들고 활성화할 수 있습니다. Github 리포지토리의 README를 사용하여 로컬 환경을 설정한 경우에도 Prodigy 전용의 별도 가상 환경을 생성하여 기본 적용되는 nlp Conda 환경과의 충돌을 방지해야 합니다.\n",
    "\n",
    "> 경고: 일반적으로 보유한 모든 기계 학습 프로젝트에 대해 새로운 가상 환경을 만드는 것이 좋습니다. 각 프로젝트에 별도의 환경이 있으면 다른 프로젝트에 필요할 수 있지만 현재 프로젝트에 대한 코드 오류를 유발할 수 있는 라이브러리를 제거하지 않고도 현재 프로젝트에 대한 관련 라이브러리를 설치할 수 있습니다. 현재 캔버스의 변경 사항이 다른 프로젝트에 대한 캔버스와 충돌하는 방식에 대해 걱정할 필요 없이 작업을 수행할 수 있는 가상 환경을 비어 있는 새 캔버스(즉, 새 라이브러리 세트)로 생각하십시오.\n",
    "\n",
    "```bash\n",
    "$ conda create -n prodigy anaconda python=3.8\n",
    "$ conda activate prodigy\n",
    "```\n",
    "\n",
    "이제 Prodigy 휠을 사용하여 디렉토리로 이동하여 패키지를 설치하십시오. 이것이 작동하지 않으면 전체 파일 이름으로 휠을 지정해야 할 수도 있습니다.\n",
    "\n",
    "```bash\n",
    "$ pip install prodigy*.whl\n",
    "```\n",
    "\n",
    "또한 이 가상 환경에 spaCy를 설치하고 아직 다운로드하지 않은 경우 en\\_core\\_web\\_lg 모델을 다운로드해야 합니다.\n",
    "\n",
    "> 경고: 2021년 3월부터 Prodigy는 SpaCy 3.x를 지원하지 않습니다(따라서 변압기 기반 파이프라인 없음). 가까운 장래에 Prodigy가 SpaCy 3.x에 대한 지원을 도입할 것으로 예상하지만 지금은 SpaCy 2.x 및 en_core_web_lg 모델과 함께 작업해야 합니다.\n",
    "\n",
    "```bash\n",
    "$ pip install -U spacy[cuda110]==2.3.5\n",
    "$ pip install -U spacy-lookups-data==1.0.0\n",
    "$ pip install cupy-cuda110==8.5.0\n",
    "$ python -m spacy download en_core_web_lg\n",
    "```\n",
    "\n",
    "이제 Prodigy에 로드할 파일을 준비하겠습니다. NER의 경우 열 이름이 \"텍스트\"인 텍스트 스니펫의 CSV가 필요합니다. AG News 데이터 세트의 설명을 텍스트 스니펫으로 사용하고 Prodigy에서 주석을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare text for annotation in Prodigy\n",
    "train_prodigy_ner = data.copy()\n",
    "train_prodigy_ner = train_prodigy_ner.description\n",
    "train_prodigy_ner.rename(\"text\",inplace=True)\n",
    "train_prodigy_ner.to_csv(cwd +\n",
    "                         \"/data/ag_dataset/ner/raw/train_prodigy_ner.csv\",\n",
    "                         index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터를 Prodigy에 로드하고 데이터에 주석을 달 수 있습니다. 관심 있는 세 가지 주요 엔터티(ORG, PERSON 및 GPE)와 네 번째 새 엔터티(TICKER)에 대한 데이터에 주석을 추가합니다.\n",
    "\n",
    "이 주석을 수행하기 위해 *ner.manual*이라는 Prodigy 레시피를 사용합니다(그림 3-2). 이 레시피를 사용하면 엔티티 범위를 강조 표시하고 해당 레이블을 선택하여 텍스트의 엔티티 범위를 표시할 수 있습니다.각주:[이러한 Prodigy 레시피에 대한 자세한 내용은 https://prodi.gy/docs/recipes#training[Prodigy 웹사이트]를 방문하세요. ]\n",
    "\n",
    "![ner.manual 레시피](images/hulp_0302.png)\n",
    "\n",
    "명령줄에서 레시피의 이름(ner.manual), 주석을 저장할 데이터 세트의 이름(예: ag_data_ner_ticker), spaCy 모델(예: en_core_web_lg 또는 공백)을 지정해야 합니다. en 빈 모델로 시작하려는 경우), 텍스트 소스(이 경우 train_prodigy_ner.csv의 경로) 및 텍스트에 주석을 달기 위해 Prodigy UI에서 사용할 수 있는 엔터티 레이블입니다.\n",
    "\n",
    "```bash\n",
    "$ python -m prodigy ner.manual <dataset> <spacy_model> <source> \\\n",
    " --label ORG,PERSON,GPE,TICKER\n",
    "```\n",
    "\n",
    "성공하면 명령줄에 이 메시지가 표시됩니다.\n",
    "\n",
    "✨  Starting the web server at http://localhost:8080 ...\n",
    "Open the app in your browser and start annotating!\n",
    "\n",
    "Go ahead and copy the URL into your web browser and you should see an annotation UI such as the one shown in Figure 3-3.\n",
    "\n",
    "![Prodigy NER Annotation UI](images/hulp_0303.png)\n",
    "\n",
    "이제 그림 3-4와 같이 범위를 강조 표시하고 올바른 엔터티로 데이터에 레이블을 지정할 수 있습니다. 큰 녹색 확인 표시 상자를 클릭하여 다음 예제로 진행합니다(또는 키보드에서 \"a\" 키를 누릅니다). 답이 확실하지 않아 예제를 건너뛰려면 키보드에서 \"스페이스\"를 누르십시오.\n",
    "\n",
    "![Prodigy NER Annotation UI - Annotating First Example](images/hulp_0304.png)\n",
    "\n",
    "수백 개에 주석을 달고 UI의 왼쪽 상단 모서리에 있는 \"신동\"이라는 단어 옆에 있는 플로피 디스크 기호를 클릭하여 저장해 보겠습니다. 적절한 미세 조정 모델에는 수백 개의 주석이면 충분하지만 항상 그렇듯이 주석이 많을수록 모델의 성능이 향상됩니다.\n",
    "\n",
    "주석이 준비되면 *data-to-spacy* Prodigy 레시피를 사용하여 spaCy의 JSON 형식으로 NER 주석을 출력할 수 있습니다(그림 3-5).\n",
    "\n",
    "![data-to-spacy Prodigy Recipe](images/hulp_0305.png)\n",
    "\n",
    "\n",
    "이 레시피의 경우 출력 경로(모델 학습용), 평가 출력 경로(모델 평가용), 언어(여기서는 \"en\"), --ner 태그를 사용하여 ner 데이터 세트를 지정해야 합니다.\n",
    "\n",
    "```bash\n",
    "$ python -m prodigy data-to-spacy <output> <eval_output> --lang en \\\n",
    "--ner ag_data_ner_ticker\n",
    "```\n",
    "\n",
    "이 명령은 주석을 JSON 형식으로 출력하지만 spaCy v3.0(2021년 1월 출시)부터 spaCy의 주요 데이터 형식은 바이너리 형식입니다. spaCy를 사용하여 훈련하기 전에 JSON 형식을 이진 형식으로 변환해야 합니다. SpaCy에는 이에 대한 변환 레시피가 있으며 지금 사용할 것입니다.\n",
    "\n",
    "> 참고: 바이너리 형식으로 변환하는 이유는 Prodigy에서 내보내기를 마친 후 주석을 사용하여 SpaCy 3.x에서 변환기 기반 모델을 미세 조정하기 때문입니다.\n",
    "\n",
    "![Convert spaCy Recipe](images/hulp_0305b.png)\n",
    "\n",
    "```bash\n",
    "$ python -m spacy convert <path-to-json> <path-for-binary-output>\n",
    "```\n",
    "\n",
    " 좋습니다! 이제 이 주석 데이터로 spaCy 모델을 미세 조정할 준비가 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Custom NER Model using SpaCy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금 프로디지 섹션을 건너뛰었더라도 걱정하지 마십시오. 학습 및 평가 주석을 생성했으며 다음 섹션에서 사용할 수 있도록 했습니다.\n",
    "\n",
    "> 팁: 이 시점에서 로컬 컴퓨터에서 SpaCy 모델을 개발하는 경우 \"prodigy\"라는 Conda 환경을 비활성화하고 \"applied_nlp\"라는 기본 Conda 환경을 활성화하십시오.\n",
    "\n",
    "우리는 두 개의 개별 NER 모델을 훈련할 것입니다. 먼저 전이 학습을 사용하여 NER 모델을 교육합니다. 전이 학습을 수행하기 위해 [RoBERTa](https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/)라는 변환기 모델을 사용합니다. 2019년에 Facebook에서 출시한 사전 훈련된 대규모 언어 모델입니다. 둘째, 변환기 모델과 GPU 없이 NER 모델을 훈련하고 CPU 기반 훈련 파이프라인에만 의존할 것입니다. 이를 통해 변압기 기반 GPU 지원 성능과 표준 CPU 기반 성능을 비교할 수 있습니다.\n",
    "\n",
    "먼저 트랜스포머 기반 모델을 학습시켜 보겠습니다. 그림 3-6과 같이 spaCy에서 **train** 명령을 사용합니다. 각주:[train 명령에 대한 자세한 내용은 [공식 spaCy 문서](https://spacy.io/api/를 참조하세요. cli#train).\\]\n",
    "\n",
    "![SpaCy Train Command](images/hulp_0306.png)\n",
    "\n",
    "이 명령의 경우 GPU에서 교육을 활성화하려면 구성 경로, 출력 경로, GPU 태그를 지정해야 합니다. 교육 구성 경로에 대한 요구 사항은 spaCy v3.0의 새로운 기능입니다. 학습 구성은 모델 개발을 위한 모든 설정과 하이퍼파라미터를 설정하는 파일입니다.\n",
    "\n",
    "```bash\n",
    "    $ python -m spacy train <config_path> --output <output_path> \\\n",
    "    --gpu-id 0\n",
    "```\n",
    "\n",
    "먼저 교육용으로 이 구성 파일을 생성해 보겠습니다. Surprise! 처음부터 구성 파일을 생성하기 위한 spaCy 레시피가 있습니다. 이 명령의 경우 lang(en), 수정해야 하는 파이프라인 구성 요소(ner), 최적화 태그를 지정해야 합니다. (더 빠른 추론을 위한 \"효율성\"/더 작은 모델 또는 더 높은 정확도/느리고 더 큰 모델을 위한 \"정확도\"), gpus 사용 여부, 존재하는 경우 gpus 사용 여부\n",
    "\n",
    "![SpaCy Init Config](images/hulp_0306b.png)\n",
    "\n",
    "```bash\n",
    "    $ python -m spacy init config <config_path> --lang --pipeline \\\n",
    "    --optimize --gpu --force \n",
    "```\n",
    "\n",
    "또 다른 옵션은 spaCy의 공식 웹사이트에서 [훈련 구성 UI](https://spacy.io/usage/training#config)를 사용하여 NER용 구성 파일의 모범 사례 버전을 생성하는 것입니다. 대부분의 프로젝트를 시작하려면 spaCy가 모델 실험을 기반으로 발견한 모범 사례로 이 구성 위젯을 업데이트하기 때문에 여기에서 시작하는 것이 가장 좋습니다. 이것이 우리가 사용할 것입니다. 빈 변환기 기반 템플릿(GPU 활성화)을 시작합니다.\n",
    "\n",
    "그림 3.6c에 표시된 init fill-config라는 또 다른 spaCy 명령을 사용하여 spaCy에서 이 기본 NER 템플릿을 자동으로 채워야 합니다.\n",
    "\n",
    "![SpaCy Init Fill-Config](images/hulp_0306c.png)\n",
    "\n",
    "이 명령은 구성 파일의 입력 경로(spaCy 웹 사이트에서 다운로드)와 출력 경로의 두 가지 매우 간단한 매개 변수를 사용합니다. 이 명령은 spaCy의 위젯에서 생성된 기본 템플릿의 나머지 구성 요소를 자동으로 채워 최종 출력 구성 파일을 생성합니다.\n",
    "\n",
    "```bash\n",
    "    $ python -m spacy init fill-config <config_path_original> \\ \n",
    "    <config_path_new> \n",
    "```\n",
    "\n",
    "지금 이 명령을 실행한 다음 교육을 진행해 보겠습니다. 우리는 30 epoch 동안 훈련할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Auto-fill base template\n",
    "ner_path = \"/data/ag_dataset/ner/\"\n",
    "\n",
    "# the downloaded file from spaCy\n",
    "config_file_path_input = cwd + ner_path + \"config_spacy_template_gpu_blank.cfg\"\n",
    "\n",
    "# the output file we will use for training\n",
    "config_file_path_output = cwd + ner_path + \"config_final_gpu_blank.cfg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m spacy init fill-config \"$config_file_path_input\" \\ \n",
    "\"$config_file_path_output\" \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Train SpaCy model on NER annotations\n",
    "output_path = cwd + \"/models/ag_dataset/ner/ner-gpu-blank\"\n",
    "train_path = cwd + \"/data/ag_dataset/ner/annotations/binary/train\"\n",
    "dev_path = cwd + \"/data/ag_dataset/ner/annotations/binary/eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m spacy train \"$config_file_path_output\" \\ \n",
    "--output \"$output_path\" --paths.train \"$train_path\" \\ \n",
    "--paths.dev \"$dev_path\" --training.max_epochs 30 --gpu-id 0 --verbose\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 3-7은 결과를 보여줍니다. 보시다시피 모델은 30 에포크 내에 95 이상의 F1 점수를 달성합니다.\n",
    "\n",
    "![SpaCy NER - Transformer GPU-Based](images/hulp_0307.png)\n",
    "\n",
    "이번에는 트랜스포머 기반 모델과 GPU 없이 전이 학습 없이 두 번째 모델을 훈련해 보겠습니다.\n",
    "\n",
    "먼저 구성 파일을 생성한 다음 이 구성 파일을 사용하여 30 epoch 동안 모델을 교육합니다. 우리가 원하는 GPU 태그가 없습니다. GPU 태그가 없으면 변환기 기반 모델을 사용하지 않는 구성 파일이 생성됩니다. 이 두 번째 모델은 RoBERTa 모델의 전이 학습을 사용하지 않는 반면 우리가 개발한 첫 번째 모델은 전이 학습을 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Generate config file\n",
    "# the output file we will use for training\n",
    "ner_path = \"/data/ag_dataset/ner\"\n",
    "config_file_path_output = cwd + new_path + \"config_final_no_gpu_blank.cfg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m spacy init config \"$config_file_path_output\" --lang en \\ \n",
    "--pipeline ner --optimize efficiency --force \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Train SpaCy model on NER annotations\n",
    "output_path = cwd + \"/models/ag_dataset/ner/ner-no-gpu-blank\"\n",
    "train_path = cwd + \"/data/ag_dataset/ner/annotations/binary/train\"\n",
    "dev_path = cwd + \"/data/ag_dataset/ner/annotations/binary/eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m spacy train \"$config_file_path_output\" \\ \n",
    "--output \"$output_path\" --paths.train \"$train_path\" \\ \n",
    "--paths.dev \"$dev_path\" --gpu-id 0 --training.max_epochs 30 --verbose\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 모델(그림 3-8)의 결과는 나쁘지는 않지만 첫 번째 모델의 결과만큼 좋지는 않습니다. 사전 훈련된 대규모 언어 모델의 전이 학습을 사용하지 않는 이 두 번째 모델은 변환기 기반 모델의 F1 점수 95에 훨씬 못미치는 90에 가까운 F1 점수를 달성합니다.\n",
    "\n",
    "![SpaCy NER - No Transformer CPU-Based](images/hulp_0308.png)\n",
    "\n",
    "트랜스포머 기반 모델이 비 트랜스포머 기반 모델보다 성능이 더 좋기 때문에(예상대로) 이 미세 조정된 트랜스포머 기반 모델(AG News Dataset에서 미세 조정됨)을 원래 트랜스포머 기반 spaCy 버전( `en_core_web_trf`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom NER Model vs. Original NER Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세 조정된 변환기 기반 모델을 원래 `en_core_web_trf`와 비교하는 것은 동일 비교가 아닙니다. 미세 조정 모델은 4개의 엔터티 유형(ORG, PERSON, GPE 및 TICKER)만 지원하는 반면 원래 `en_core_web_trf `는 더 많은 엔터티 유형을 지원합니다(하지만 AG News 데이터 세트에 대해 방금 주석을 추가한 새 엔터티 유형인 TICKER는 지원하지 않음).\n",
    "\n",
    "그럼에도 불구하고 AG News 데이터 세트의 기사 설명 샘플에서 두 모델을 비교하고 어떤 모델이 더 나은 성능을 보이는지 확인할 수 있습니다. 이를 통해 RoBERTa 모델을 미세 조정하면 원래 spaCy 모델에 비해 데이터 세트의 NER 성능이 개선되었는지 확인할 수 있습니다.\n",
    "\n",
    "두 모델의 결과를 비교하기 전에 미세 조정된 NER 모델을 로드하고 모델의 메타데이터를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load custom NER model\n",
    "# To use GPU, uncomment the GPU-related code below\n",
    "\n",
    "# spacy.require_gpu()\n",
    "custom_ner_model = spacy.load(cwd + \\\n",
    "    '/models/ag_dataset/ner/ner-gpu-blank/model-best')\n",
    "\n",
    "# View metadata of the model\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(custom_ner_model.meta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세 조정된 NER 모델은 4개의 엔터티 유형만 지원하지만 F1 점수는 꽤 좋습니다. GPE의 경우 97, ORG의 경우 93, PERSON의 경우 96, TICKER의 경우 98입니다. 이에 비해 원래 spaCy 모델의 F1 점수는 GPE의 경우 95, ORG의 경우 90, PERSON의 경우 95입니다(그리고 원래 spaCy 모델이 지원하지 않는 TICKER의 경우 F1이 없음). F1 점수가 서로 다른 데이터 세트에서 측정되었기 때문에 비교는 사과 대 사과가 아니지만 상대적인 성능 감각을 제공합니다.\n",
    "\n",
    "이제 NER용 내장 spaCy 시각화 도우미를 사용하여 두 모델을 비교해 보겠습니다.\n",
    "\n",
    "> 참고: 원본과 기본을 같은 의미로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Compare NER results on Descriptions: Original/Base vs. Custom\n",
    "# To use GPU, uncomment the GPU-related code below\n",
    "\n",
    "from spacy import displacy\n",
    "import random\n",
    "\n",
    "#spacy.require_gpu()\n",
    "base_model = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "options = {\"ents\": [\"ORG\",\"PERSON\",\"GPE\",\"TICKER\"]}\n",
    "\n",
    "for j in range(3):\n",
    "    i = random.randint(0, len(data))\n",
    "    print(\"Article\",i)\n",
    "    doc_base = base_model(data.loc[i,\"description\"])\n",
    "    doc_custom = custom_ner_model(data.loc[i,\"description\"])\n",
    "    print(\"Base Model NER:\")\n",
    "    displacy.render(doc_base, style=\"ent\", options=options, jupyter=True)\n",
    "    print(\"Custom Model NER:\")\n",
    "    displacy.render(doc_custom, style=\"ent\", options=options, jupyter=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 3-10에서 볼 수 있듯이 두 모델의 NER 결과는 비슷합니다(미세 조정된 모델의 경우 약간 높지만 F1 점수가 다소 유사하기 때문에 이치에 맞습니다). 예를 들어 기사 55405의 경우 기본 모델과 미세 조정된 모델 모두 \"Apple\"을 ORG로 캡처합니다. 기사 4145의 경우 기본 모델에서 ORG로 \"NewsFactor\"가 누락되고 ORG로 \"Cingular Wireless\"가 누락되며 미세 조정된 모델이 캡처합니다. 미세 조정된 모델은 NYSE를 ORG로 놓치고 \"AWS\"를 TICKER로 캡처합니다. 문서 106431의 경우에도 결과가 동일합니다.\n",
    "\n",
    "![Article Examples](images/hulp_0310.png)\n",
    "\n",
    "미세 조정된 모델이 전반적으로 기본 모델보다 더 나은 성능을 보이는 반면, 미세 조정된 모델이 주어진 예에서 항상 기본 모델보다 성능이 뛰어난 것은 아닙니다. 이를 확인하려면 위의 코드 스니펫을 테스트하여 기본 모델의 결과를 미세 조정된 모델의 결과와 비교하십시오. 기본 모델이 더 잘 수행되는 인스턴스를 확실히 찾을 수 있습니다.\n",
    "\n",
    "축하해요! 우리는 RoBERTa 모델을 미세 조정하고 Prodigy에서 AG News 데이터 세트의 작은 비율에 주석을 달고 spaCy를 사용하여 교육함으로써 주식 시세 표시기에 대한 새 엔터티를 추가했습니다. 그런 다음 미세 조정된 모델을 원래 spaCy 모델과 비교하고 미세 조정된 모델에서 (일반적으로) 더 나은 성능을 확인했습니다. 또한 미세 조정된 모델이 이제 예상대로 주식 시세 표시기에 태그를 지정하고 있음을 확인할 수 있습니다.\n",
    "\n",
    "이것은 두 가지 이유로 큰 성과입니다. 첫째, 우리의 작업은 작은 주석 세트(단지 수백 개)에서도 사전 훈련된 대규모 언어 모델을 미세 조정하면 성능이 향상된다는 것을 보여줍니다. 모델을 처음부터 훈련할 필요가 없습니다. 사전 학습된 언어 모델에서 일부 사전 학습을 활용하고 이를 발판으로 사용하여 특정 말뭉치에서 특정 작업의 성능을 향상시킬 수 있습니다. 전이 학습은 새로운 모델 구축 시간을 크게 줄여 실무자에게 큰 이점을 제공합니다. 둘째, 맞춤형 엔터티 유형(예: 주식 시세 표시기)에 대한 고유한 NER 모델을 개발하는 것이 얼마나 쉬운지 보여 주었습니다. 새 모델 개발은 매우 고통스럽지 않습니다. 새로운 맞춤형 모델을 빠르게 시작하고 실행할 수 있습니다.\n",
    "\n",
    "다음 섹션에서는 사용자 지정 NER 모델에 사용한 것과 동일한 기술 중 일부를 적용하여 두 번째 NLP 작업인 텍스트 분류를 수행해 보겠습니다. 이러한 기술에는 이 텍스트 분류 작업에서 우수한 성능을 달성하기 위해 데이터에 주석을 달고 사전 훈련된 대규모 언어 모델을 미세 조정하는 것이 포함됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Task #2 - Text Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명명된 엔터티 인식 수행을 완료했으므로 이제 두 번째 NLP 작업인 텍스트 분류로 넘어가겠습니다. 텍스트 분류는 NLP의 매우 일반적인 적용입니다. 애플리케이션에는 뉴스 기사를 주제 기반 카테고리로 분류하는 뉴스 앱, 이메일 앱의 스팸/스팸 아님 기능, Facebook 및 기타 소셜 플랫폼의 실제 뉴스/가짜 뉴스 분류 모델이 포함됩니다.\n",
    "\n",
    "요약하면 AG News 열차 데이터 세트의 모든 기사는 이미 Business, Sci\\_Tech, Sports 및 World의 네 가지 클래스 중 하나로 분류되어 있습니다. 주석을 모두 건너뛰고 이러한 레이블을 사용하여 spaCy를 사용하여 텍스트 분류 모델을 훈련할 수 있습니다. 그러나 실제 세계에서는 이와 같이 미리 주석이 달린 데이터 세트를 거의 사용하지 않습니다. 대신 일반적으로 처음부터 데이터에 주석을 다는 연습을 거쳐야 합니다.\n",
    "\n",
    "미리 훈련된 대규모 언어 모델을 미세 조정하여 데이터에 주석을 달고 텍스트 분류 모델을 생성하는 것이 얼마나 쉬운지 보여주기 위해 Prodigy를 사용하여 처음부터 몇 가지 예에 주석을 달고 생성한 레이블에서 텍스트 분류 모델을 훈련해 보겠습니다.\n",
    "\n",
    "이전과 마찬가지로 Prodigy에서 라이선스를 구매하지 않으려는 경우(또는 [Labelbox](https://labelbox.com/)와 같은 다른 주석 플랫폼에서 데이터에 주석을 추가하려는 경우) 이 다음 섹션을 건너뛸 수 있습니다. Prodigy에서 주석을 내보내고 텍스트 분류 모델을 훈련하는 데 사용할 수 있도록 하므로 Prodigy 주석을 건너뛰기로 결정한 경우 걱정하지 마십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate via Prodigy - Text Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER에서 했던 것처럼 텍스트 분류를 위해 Prodigy에 로드할 파일을 준비하겠습니다. 이전과 마찬가지로 열 이름이 \"text\"인 텍스트 스니펫의 CSV가 필요합니다. AG News Dataset의 제목과 설명(NER에 대해 했던 것과 같은 설명이 아님)을 텍스트 스니펫으로 사용하고 Prodigy에서 주석을 추가합니다.\n",
    "\n",
    "훈련 데이터 세트를 두 개로 나누겠습니다. 하나는 Prodigy에서 사용하고 다른 하나는 텍스트 분류 모델을 평가하는 데 사용합니다. 이러한 \"textcat_train\" 및 \"textcat_eval\" 집합을 각각 호출할 수 있습니다. 이 분할을 수행하기 위해 Scikit-Learn.footnote에서 train_test_split 함수를 사용합니다.[train_test_split 함수에 대한 자세한 내용은 [공식 Scikit-Learn 문서](https://scikit-learn.org/stable/modules/를 참조하세요. 생성/sklearn.model_selection.train_test_split.html).]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# To train and evaluate text classification models in Prodigy\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Prepare for Text Classification\n",
    "textcat = data.copy()\n",
    "textcat[\"text\"] = textcat[\"title\"] + str(\" \") + textcat[\"description\"] \n",
    "textcat[\"label\"] = textcat[\"class_name\"]\n",
    "textcat.drop(columns=[\"class_index\",\"title\",\"description\",\"class_name\"],\n",
    " inplace=True)\n",
    "textcat_train, textcat_eval = train_test_split(textcat, test_size=0.2,\n",
    " random_state=2020, stratify=textcat.label)\n",
    " \n",
    "textcat_train.to_csv(cwd +\n",
    " '/data/ag_dataset/textcat/raw/train_prodigy_textcat_train_with_labels.csv',\n",
    " index=False)\n",
    "\n",
    "textcat_eval.to_csv(cwd +\n",
    " '/data/ag_dataset/textcat/raw/train_prodigy_textcat_eval.csv',\n",
    " index=False)\n",
    " \n",
    "textcat_train = textcat_train.text\n",
    "textcat_train.to_csv(cwd +\n",
    " '/data/ag_dataset/textcat/raw/train_prodigy_textcat_train_without_labels.csv',\n",
    " index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터를 Prodigy에 로드하고 데이터에 주석을 달 수 있습니다. Business, Sci_Tech, Sports 및 World의 네 가지 상호 배타적 레이블을 사용하여 데이터에 주석을 추가합니다. 이를 위해 *textcat.manual*이라는 Prodigy 레시피를 사용합니다(그림 3-13). 이 레시피를 사용하면 텍스트에 적용되는 범주에 수동으로 주석을 달 수 있습니다. --label 플래그를 사용하여 레이블을 설정하고 --exclusive 플래그를 사용하여 레이블을 상호 배타적으로 지정합니다. 즉, 예제에는 여러 개의 class/labels가 아닌 하나의 올바른 클래스만 있을 수 있습니다.주석:[이러한 Prodigy 레시피에 대한 자세한 내용은 https://prodi.gy/docs/recipes#training[Prodigy 웹사이트]를 방문하세요.]\n",
    "\n",
    "![textcat.manual Prodigy Recipe](images/hulp_0313.png)\n",
    "\n",
    "\n",
    "명령줄에서 레시피의 이름(textcat.manual), 주석을 저장할 데이터세트의 이름(예: `ag_data_textcat`), 텍스트 소스(이 경우에는 `train_prodigy_textcat_train_without_labels.csv`의 경로), 텍스트에 주석을 달기 위해 Prodigy UI에서 사용할 수 있는 레이블과 --exclusive 플래그입니다.\n",
    "\n",
    "```bash\n",
    "    $ python -m prodigy textcat.manual <dataset> <source> \\\n",
    "     --label Business,Sci_Tech,Sports,World --exclusive\n",
    "```\n",
    "\n",
    "If successful, you will see this message in the command line.\n",
    "\n",
    "```bash\n",
    "✨ Starting the web server at <http://localhost:8080> …​ \\\n",
    "Open the app in your browser and start annotating!\n",
    "```\n",
    "\n",
    "계속해서 URL을 웹 브라우저에 복사하면 그림 3-14와 같이 주석 UI가 표시되어야 합니다. 왼쪽 상단 모서리에 있는 \"VIEW ID\" 옆에 \"choice\"가 보이는지 확인하십시오. 그렇지 않은 경우 --exclusive 태그를 설정하는 것을 잊었을 수 있습니다.\n",
    "\n",
    "![Prodigy Textcat Annotation UI](images/hulp_0314.png)\n",
    "\n",
    "이제 각 텍스트를 네 가지 범주 중 하나로 분류할 수 있습니다. 큰 녹색 확인 표시 상자를 클릭하여 다음 예제로 진행합니다(또는 키보드에서 \"a\" 키를 누릅니다). 답이 확실하지 않아 예제를 건너뛰려면 키보드에서 \"스페이스\"를 누르십시오.\n",
    "\n",
    "수백 개에 주석을 달고 UI의 왼쪽 상단 모서리에 있는 \"신동\"이라는 단어 옆에 있는 플로피 디스크 기호를 클릭하여 저장해 보겠습니다. 적절한 텍스트 분류 모델에는 수백 개의 주석이면 충분하지만 항상 그렇듯이 주석이 많을수록 모델의 성능이 향상됩니다.\n",
    "\n",
    "주석이 준비되면 이전에도 사용했던 **data-to-spacy** Prodigy 레시피를 사용하여 spaCy의 JSON 형식으로 주석을 출력할 수 있습니다(그림 3-15).\n",
    "\n",
    "![data-to-spacy 프로디지 레시피](images/hulp_0315.png)\n",
    "\n",
    "이 레시피의 경우 출력 경로(모델 학습용), 언어(이 경우 \"en\"), `--textcat` 플래그를 사용하는 textcat 데이터 세트 및 `--textcat-exclusive`를 지정해야 합니다. 클래스를 상호 배타적으로 취급하고 싶기 때문에 플래그입니다. 이전 섹션에서 `train_test_split`을 사용하여 생성한 레이블이 지정된 `textcat_eval` 세트가 이미 있으므로 평가 출력 경로를 설정할 필요가 없습니다.\n",
    "\n",
    "```bash\n",
    "    $ python -m prodigy data-to-spacy <output> \\\n",
    "    --lang en --textcat ag_data_textcat --textcat-exclusive\n",
    "```\n",
    "\n",
    "다음으로 spaCy 훈련을 위해 이 훈련 데이터를 JSON 형식에서 이진 형식으로 변환해 보겠습니다.\n",
    "\n",
    "```bash\n",
    "$ python -m spacy convert <path-to-json> <path-for-binary-output>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Convert from JSON to binary format for spaCy training \n",
    "# Few Labels from Prodigy Annotations\n",
    "json_path = \"/data/ag_dataset/textcat/annotations/jsons/\"\n",
    "bin_path = \"/data/ag_dataset/textcat/annotations/binary/\"\n",
    "input_path = cwd + json_path + \"train_few_labels\"\n",
    "output_path = cwd + bin_path + \"train_few_labels\"\n",
    "!python -m spacy convert \"$input_path\" \"$output_path\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 'textcat_eval' 설정을 CSV 형식에서 spaCy에서 사용할 JSON 형식으로 변환해 보겠습니다. 이를 수행하려면 먼저 **db-in** 레시피를 사용하여 CSV를 prodigy에 로드해야 합니다(그림 3-16). 이 레시피의 경우 데이터 세트 이름(예: `ag_data_textcat_eval`)과 파일 경로(예: `train_prodigy_textcat_eval.csv`의 경로)를 지정해야 합니다.\n",
    "\n",
    "![db-in Prodigy Recipe](images/hulp_0316.png)\n",
    "\n",
    "```bash\n",
    "    $ python -m prodigy db-in dataset in_file\n",
    "```\n",
    "\n",
    "성공하면 다음 메시지가 표시됩니다.\n",
    "\n",
    "```bash\n",
    "✔ Imported 24000 annotations to 'ag\\_data\\_textcat\\_eval' \\\n",
    "in database SQLite Found and keeping existing \"answer\" \\\n",
    "in 0 examples\n",
    "```\n",
    "\n",
    "이제 data-to-spacy 레시피를 사용하여 spaCy의 JSON 형식으로 내보낼 수 있습니다.\n",
    "\n",
    "```bash\n",
    "    $ python -m prodigy data-to-spacy <output> \\\n",
    "     --lang en --textcat ag_data_textcat_eval --textcat-exclusive\n",
    "```\n",
    "\n",
    "이는 `output` 경로와 `--textcat` 태그를 `ag_data_textcat_eval`로 변경해야 한다는 점을 제외하면 이전과 동일합니다.\n",
    "\n",
    "이제 'textcat_train_with_labels' 세트도 준비하겠습니다. Prodigy 주석이 달린 모델과 더 많은 레이블에서 훈련된 모델이 얼마나 잘 수행되는지 비교하기 위해 원래 레이블에서 텍스트 분류 모델을 훈련하기를 원하기 때문입니다.\n",
    "\n",
    "평가 세트를 준비하는 데 사용한 것과 동일한 단계를 반복하지만 이번에는 `textcat_train_with_labels`를 사용합니다. 이 데이터 세트를 `ag_data_textcat_train_with_labels`라고 합니다.\n",
    "\n",
    "```bash\n",
    "    $ python -m prodigy db-in dataset in_file\n",
    "    $ python -m prodigy data-to-spacy <output> \\\n",
    "     --lang en --textcat ag_data_textcat_train_with_labels --textcat-exclusive\n",
    "```\n",
    "\n",
    "이제 이 두 JSON을 spaCy 교육을 위해 이진 형식으로 변환해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Convert from JSON to binary format for spaCy training - Eval Set\n",
    "input_path = cwd + \"/data/ag_dataset/textcat/annotations/jsons/eval\"\n",
    "output_path = cwd + \"/data/ag_dataset/textcat/annotations/binary/eval\"\n",
    "!python -m spacy convert \"$input_path\" \"$output_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Convert from JSON to binary format for spaCy training\n",
    "# Full Set of Labels\n",
    "json_path = \"/data/ag_dataset/textcat/annotations/jsons/\"\n",
    "bin_path = \"/data/ag_dataset/textcat/annotations/binary/\"\n",
    "input_path = cwd + json_path + \"train_full_labels\"\n",
    "output_path = cwd + bin_path + \"train_full_labels\"\n",
    "!python -m spacy convert \"$input_path\" \"$output_path\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종습니다! 이제 주석이 달린 이 데이터로 텍스트 분류 모델을 교육할 준비가 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Text Classification Models using SpaCy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금 프로디지 섹션을 건너뛰었더라도 걱정하지 마십시오. 기차 주석을 생성하여 사용할 수 있도록 했습니다.\n",
    "\n",
    "우리는 두 개의 개별 모델을 훈련할 것입니다. 먼저 Prodigy를 사용하여 생성한 수백 개의 주석을 사용하여 텍스트 분류 모델을 훈련하고 이전에 생성한 textcat\\_eval 세트와 비교하여 평가합니다. 그런 다음 이전의 textcat\\_train 데이터 세트에 있는 전체 레이블 세트를 사용하여 두 번째 텍스트 분류 모델을 학습하고 textcat\\_eval 세트에 대해 평가합니다.\n",
    "\n",
    "시작하려면 먼저 교육용 구성 파일을 생성해 보겠습니다. 변환기 기반 모델(RoBERTa)을 사용하고 텍스트 분류 모델에 대한 전이 학습을 수행합니다. 동일한 텍스트에 대해 다른 레이블이 있을 수 있으므로 다중 레이블 분류 문제로 지정합니다. 즉, 동일한 텍스트에 대해 서로 다른 주석자가 동의하지 않기 때문에 데이터에 다르게 레이블을 지정했을 수 있습니다. 이것은 데이터에 주석을 달 때 매우 일반적인 문제입니다. 주석 작성자 간에 내부 의견 불일치/판단이 다를 수 있습니다. 모델을 교육하기 전에 모든 불일치를 검토하고 해결하거나 선택한 대로 모델을 다중 레이블 분류 모델로 설정할 수 있습니다.\n",
    "\n",
    "> 참고: 총 약 800개의 주석만 있으므로 Prodigy 주석 버전을 \"몇 가지 레이블\" 모델이라고 합니다. 96,000개의 주석에 대해 학습된 모델을 \"전체 레이블\" 모델이라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Generate config file\n",
    "# the output file we will use for training\n",
    "config_file_path_output = cwd + \"/data/ag_dataset/textcat/config_final.cfg\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m spacy init config \"$config_file_path_output\" --lang en \\\n",
    "--pipeline textcat_multilabel --optimize efficiency --gpu --force \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성공하면 그림 03-16b와 유사한 메시지가 표시됩니다. 우리는 이 모델을 다중 레이블 텍스트 분류 모델로 구성했으며, 효율성에 최적화되고 GPU를 활용하며 RoBERTa 변환기 모델을 기본 모델로 사용했습니다.\n",
    "\n",
    "![SpaCy Textcat Configuration](images/hulp_0316b.png)\n",
    "\n",
    "먼저 Prodigy 주석을 사용하여 텍스트 분류 모델을 훈련해 보겠습니다. 이전 NER 교육 과정에서 했던 것처럼 spaCy에서 train 명령을 사용할 것입니다(그림 3-17).주석:[train 명령에 대한 자세한 내용은 [공식 spaCy 문서](https://spacy. io/api/cli#train).\\]\n",
    "\n",
    "![SpaCy Train Command](images/hulp_0317.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Train model on Text Classification annotations \n",
    "# Few Labels from Prodigy\n",
    "import spacy\n",
    "annots_path = \"/data/ag_dataset/textcat/annotations/binary/\"\n",
    "output_path = cwd + \"/models/ag_dataset/textcat/few_labels\"\n",
    "train_path = cwd + annots_path + \"train_few_labels\"\n",
    "dev_path = cwd + annots_path + \"eval\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "별도의 명령을 통해 스크립트를 시작합니다.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m spacy train \"$config_file_path_output\" \\ \n",
    "--output \"$output_path\" --paths.train \"$train_path\" \\\n",
    "--paths.dev \"$dev_path\" --gpu-id 0 --training.max_epochs 30 --verbose\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 3-18은 훈련 과정의 결과를 보여줍니다.\n",
    "\n",
    "![SpaCy Text Classification Model - Prodigy Annotations](images/hulp_0318.png)\n",
    "\n",
    "보시다시피 모델은 30 epoch 후에 F1 점수 \\~83에 도달합니다. 단지 수백 개의 주석으로 모델을 훈련했다는 점을 감안할 때 이것은 여전히 ​​매우 좋은 성능입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 textcat\\_train 세트에 있는 96,000개의 원래 레이블을 사용하여 텍스트 분류 모델을 훈련해 보겠습니다(train\\_test\\_split을 사용하여 textcat\\_eval 세트에 대해 24,000개의 예가 따로 설정되었음을 기억하십시오). 이제 훨씬 더 많은 레이블에 대해 학습할 것이기 때문에 F1 점수가 훨씬 높아야 합니다.\n",
    "\n",
    "spaCy 훈련 명령은 새로운 출력 및 훈련 경로를 제외하고 이전과 동일하게 유지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Train model on Text Classification annotations\n",
    "# Full Set of Labels from AG Dataset\n",
    "import spacy\n",
    "annots_path = \"/data/ag_dataset/textcat/annotations/binary/\"\n",
    "output_path = cwd + \"/models/ag_dataset/textcat/full_labels\"\n",
    "train_path = cwd + annots_path + \"train_full_labels\"\n",
    "dev_path = cwd + annots_path + \"eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m spacy train \"$config_file_path_output\" \\\n",
    "--output \"$output_path\" --paths.train \"$train_path\" \\\n",
    "--paths.dev \"$dev_path\" --gpu-id 0 --training.max_epochs 1 --verbose\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 3-19는 훈련 과정의 결과를 보여줍니다.\n",
    "\n",
    "![SpaCy Text Classification Model - 96k Original Annotations](images/hulp_0319.png)\n",
    "\n",
    "보시다시피 원래 96k 레이블을 사용하면 모델이 단 한 번의 에포크 후에 94 이상의 F1 점수를 얻습니다. 이것은 놀라운 일이 아닙니다. 데이터가 많을수록 모델 성능이 크게 향상됩니다.\n",
    "\n",
    "엄청난! 이제 두 번째 NLP 모델 교육을 마쳤습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 장에서는 오늘날 시장에서 가장 널리 사용되고 상업적으로 관련된 NLP 라이브러리 중 하나인 spaCy를 사용하여 두 가지 매우 인기 있고 핵심적인 NLP 작업인 엔터티 인식 및 텍스트 분류를 해결하기 위한 모델을 구축했습니다. 또한 이 두 모델을 개발하기 위해 Prodigy를 사용하여 처음부터 자체 데이터에 주석을 달았습니다. 이제 NLP 모델을 시작하고 실행하는 것이 얼마나 쉬운지 훨씬 더 잘 느낄 것입니다. 이 두 모델은 모두 프로덕션에서 사용할 준비가 되었으며 11장에서 프로덕션 파이프라인에서 이를 유지하는 방법을 살펴보겠습니다.\n",
    "\n",
    "이 점은 아무리 강조해도 지나치지 않습니다. 가능하면 미리 훈련된 대규모 언어 모델로 시작한 다음 특정 말뭉치에서 특정 작업에 맞게 모델을 미세 조정하는 것이 가장 좋습니다. 사전 훈련된 모델의 사전 학습을 활용하면 이 장에서 함께 해결한 것과 같은 작업에서 정말 뛰어난 성능을 달성하는 데 훨씬 적은 수의 레이블과 훨씬 적은 시간이 필요합니다. 간단히 말해서 사전 훈련된 모델에서 학습을 전송하여 새로운 모델 빌드를 가속화하는 이 기능은 NLP를 오늘날 기업에서 뜨거운 관심 주제로 만든 것입니다.\n",
    "\n",
    "이제 최첨단 NLP와 실제 NLP 작업을 해결하는 방법에 대해 더 잘 알게 되었으므로 기본으로 돌아가 NLP를 잘 수행하는 데 필요한 기본 지식을 구축해 보겠습니다. 단어 임베딩, RNN 및 변환기에 이어 다음 장에서 전처리 및 토큰화부터 시작하겠습니다. 이 책의 뒷부분에서 기계 학습 모델의 생산화에 대해 논의할 때 이러한 모델로 돌아갈 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
